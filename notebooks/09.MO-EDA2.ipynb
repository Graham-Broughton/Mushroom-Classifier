{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from os import environ\n",
    "import tqdm.contrib.concurrent as tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(':'.join(environ.get(\"PYTHONPATH\", \".\").split(\":\")[:2]))\n",
    "data = root / 'data' / 'MO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data / 'MO_images.csv')\n",
    "train = pd.read_csv('../training/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list403 = []\n",
    "\n",
    "def download(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(data / 'images' / Path(url).name, 'wb') as handle:\n",
    "            handle.write(response.content)\n",
    "        pass\n",
    "    else:\n",
    "        list403.append(Path(url).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data / 'images').mkdir(exist_ok=True)\n",
    "tqdm.thread_map(download, df['image'].values.tolist(), max_workers=500)\n",
    "\n",
    "pickle.dump(list403, open(data / 'list4032.pkl', 'wb'))\n",
    "df = df.drop(df[df['file_name'].isin(list403)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file_name']= df['image'].str.split('/').str[-1]\n",
    "df['file_path'] = str(data / 'images') + '/' + df['file_name']\n",
    "\n",
    "df.loc[:, [\"family\", \"genus\", \"class\", \"order\", \"phylum\"]] = df.loc[:, [\"family\", \"genus\", \"class\", \"order\", \"phylum\"]].replace(\"[',]\", \"\", regex=True)\n",
    "df = df[df['name'].str.split(' ').str.len() > 1]\n",
    "df.loc[df['dataset'] == '2019', \"file_path\"] = df.loc[df['dataset'] == '2019', \"file_path\"].replace(r\"train_val2019/\", '', regex=True)\n",
    "\n",
    "df = df.drop_duplicates(subset='file_name')\n",
    "df = df.replace(f'^(https?://)([^/]+)/images(/.+)', r'\\1images.\\2\\3', regex=True)\n",
    "\n",
    "df[['height', 'width']] = 480, 640\n",
    "df['dataset'] = 'MO'\n",
    "\n",
    "df.drop(['created', 'license', 'rightsHolder'], axis=1, inplace=True)\n",
    "\n",
    "full = pd.concat([train.drop(['specific_epithet', 'dset', 'class_id'], axis=1), df.drop('image', axis=1)], ignore_index=True)\n",
    "full['genus'] = full['name'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(df, column, fam, order, clas, phylum):\n",
    "    df.loc[df['genus'] == column, 'family'] = fam\n",
    "    df.loc[df['genus'] == column, 'order'] = order\n",
    "    df.loc[df['genus'] == column, 'class'] = clas\n",
    "    df.loc[df['genus'] == column, 'phylum'] = phylum\n",
    "    df.loc[df['genus'] == column, 'kingdom'] = \"Fungi\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kingdom      57888\n",
       "name             0\n",
       "family       58225\n",
       "phylum       57888\n",
       "order        58019\n",
       "genus            0\n",
       "class        57888\n",
       "file_name        0\n",
       "height           0\n",
       "width            0\n",
       "dataset          0\n",
       "file_path        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = full.fillna(full.groupby(\"genus\").transform(lambda x: x.mode().iloc[0]))\n",
    "\n",
    "with open('fill_taxa.txt') as f:\n",
    "    for line in f:\n",
    "        line = line.split()\n",
    "        line = [x.replace('\",', '').replace('\"', '').replace(')', '') for x in line]\n",
    "        full = fill(full, line[3], line[4], line[5], line[6], line[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../training/data/images > ../training/data/file_list.txt\n",
    "\n",
    "with open(data / 'file_list.txt', 'r') as f:\n",
    "    file_list = f.read().splitlines()\n",
    "\n",
    "mo = full.loc[full['dataset'] == 'MO']\n",
    "other = full.loc[full['dataset'] != 'MO']\n",
    "\n",
    "file_list = set(file_list)\n",
    "fset = set(mo['file_name'])\n",
    "missing = fset - file_list\n",
    "\n",
    "full = full.loc[~full['file_name'].isin(missing)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_list = []\n",
    "for file in file_list:\n",
    "    if (data / 'images' / file).stat().st_size < 1000:\n",
    "        empty_list.append(line)\n",
    "\n",
    "full = full.loc[~full['file_name'].isin(empty_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['class_id'] = full['name'].astype('category').cat.codes\n",
    "class_dict = full.set_index('class_id')['name'].to_dict()\n",
    "\n",
    "full.to_csv(root / 'training' / 'data' / 'train_full.csv', index=False)\n",
    "pickle.dump(class_dict, open(root / 'training' / 'data' / 'class_dict_full.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = full.groupby(\"name\").size().sort_values()\n",
    "names = group[group > 50].reset_index()['name'].to_list()\n",
    "full = full[full['name'].isin(names)]\n",
    "\n",
    "full['class_id'] = full['name'].astype(\"category\").cat.codes\n",
    "\n",
    "full.to_csv(root / 'training' / 'data' / 'train_full_smaller.csv', index=False)\n",
    "pickle.dump(full.set_index('class_id')['name'].to_dict(), open(root / 'training' / 'data' / 'class_dict_full_smaller.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
