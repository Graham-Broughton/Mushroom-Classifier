{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":80469,"status":"ok","timestamp":1696379058982,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"_ga4wuA-bnHH","outputId":"ebd15dbb-dd56-4254-e1b6-05374910fe1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow==2.10.0\n","  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n","Requirement already satisfied: flatbuffers\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.5.26)\n","Requirement already satisfied: gast\u003c=0.4.0,\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.4.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.58.0)\n","Requirement already satisfied: h5py\u003e=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.9.0)\n","Collecting keras\u003c2.11,\u003e=2.10.0 (from tensorflow==2.10.0)\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-preprocessing\u003e=1.1.1 (from tensorflow==2.10.0)\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang\u003e=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (16.0.6)\n","Requirement already satisfied: numpy\u003e=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.23.5)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.1)\n","Collecting protobuf\u003c3.20,\u003e=3.9.2 (from tensorflow==2.10.0)\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (67.7.2)\n","Requirement already satisfied: six\u003e=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n","Collecting tensorboard\u003c2.11,\u003e=2.10 (from tensorflow==2.10.0)\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.34.0)\n","Collecting tensorflow-estimator\u003c2.11,\u003e=2.10.0 (from tensorflow==2.10.0)\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.3.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.5.0)\n","Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.14.1)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow==2.10.0) (0.41.2)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (0.4.6)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (3.4.4)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (2.31.0)\n","Collecting tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 (from tensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (1.8.1)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (2.3.7)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (5.3.1)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (0.3.0)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (4.9)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (3.2.0)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (2.0.5)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (2023.7.22)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (2.1.3)\n","Requirement already satisfied: pyasn1\u003c0.6.0,\u003e=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (0.5.0)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003c2.11,\u003e=2.10-\u003etensorflow==2.10.0) (3.2.2)\n","Installing collected packages: keras, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, tensorboard, tensorflow\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.12.0\n","    Uninstalling keras-2.12.0:\n","      Successfully uninstalled keras-2.12.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.1\n","    Uninstalling tensorboard-data-server-0.7.1:\n","      Successfully uninstalled tensorboard-data-server-0.7.1\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.0\n","    Uninstalling tensorboard-2.12.0:\n","      Successfully uninstalled tensorboard-2.12.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.12.0\n","    Uninstalling tensorflow-2.12.0:\n","      Successfully uninstalled tensorflow-2.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","orbax-checkpoint 0.4.1 requires jax\u003e=0.4.9, but you have jax 0.3.25 which is incompatible.\n","tensorflow-datasets 4.9.3 requires protobuf\u003e=3.20, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-metadata 1.14.0 requires protobuf\u003c4.21,\u003e=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.10.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install tensorflow==2.10.0"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34061,"status":"ok","timestamp":1696379108812,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"PKiDhRvyNwiw","outputId":"44118253-260f-4f3a-d0e6-7acee94bdf37"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Mushroom-Classifier\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","%cd /content/drive/MyDrive/Mushroom-Classifier"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7017,"status":"ok","timestamp":1696379115825,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"LfAu_aLnNo7l","outputId":"a0a3ad8d-dd89-4ea0-90ec-0db3cfee5e29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensorflow version 2.10.0\n"]}],"source":["import math, re, os, pickle\n","import tensorflow as tf\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n","from src.models.swintransformer import SwinTransformer\n","print(f\"Tensorflow version {tf.__version__}\")\n","AUTO = tf.data.experimental.AUTOTUNE\n","\n","# os.environ['PYTHONPATH'] = f'{os.getcwd()}'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11511,"status":"ok","timestamp":1696379127332,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"PBI-WAppNo7s","outputId":"5abbf3dd-aa7d-4da3-d0b1-ad47fa2c61c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of accelerators:  8\n"]}],"source":["# Detect hardware\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","except ValueError:  # If TPU not found\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","else:\n","    strategy = tf.distribute.get_strategy()\n","print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":522,"status":"ok","timestamp":1696379127836,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"AXjXcpF5No7t"},"outputs":[],"source":["GCS_DS_PATH = \"gs://mush-img-repo\"\n","\n","IMAGE_SIZE = [224, 224] # At this size, a GPU will run out of memory. Use the TPU.\n","EPOCHS = 12\n","BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n","\n","GCS_PATH_SELECT = {\n","    192: f'{GCS_DS_PATH}/tfrecords-jpeg-192x192',\n","    224: f'{GCS_DS_PATH}/tfrecords-jpeg-224x224',\n","    331: f'{GCS_DS_PATH}/tfrecords-jpeg-331x331',\n","    512: f'{GCS_DS_PATH}/tfrecords-jpeg-512x512',\n","}\n","GCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n","\n","TRAINING_FILENAMES = tf.io.gfile.glob(f'{GCS_PATH}/train*.tfrec')\n","VALIDATION_FILENAMES = tf.io.gfile.glob(f'{GCS_PATH}/val*.tfrec')\n","\n","class_dict = pickle.load(open('src/class_dict.pkl', 'rb'))"]},{"cell_type":"markdown","metadata":{"id":"nnHHCJk-No7v"},"source":["## Visualization Utils"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1696379127837,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"yTKGP-V2No7x"},"outputs":[],"source":["# numpy and matplotlib defaults\n","np.set_printoptions(threshold=15, linewidth=80)\n","\n","def batch_to_numpy_images_and_labels(data):\n","    images, labels = data\n","    numpy_images = images.numpy()\n","    numpy_labels = labels.numpy()\n","    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n","        numpy_labels = [None for _ in enumerate(numpy_images)]\n","    # If no labels, only image IDs, return None for labels (this is the case for test data)\n","    return numpy_images, numpy_labels\n","\n","def title_from_label_and_target(label, correct_label):\n","    if correct_label is None:\n","        return class_dict[label], True\n","    correct = (label == correct_label)\n","    return \"{} [{}{}{}]\".format(class_dict[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n","                                class_dict[correct_label] if not correct else ''), correct\n","\n","def display_one_flower(image, title, subplot, red=False, titlesize=16):\n","    plt.subplot(*subplot)\n","    plt.axis('off')\n","    plt.imshow(image)\n","    if len(title) \u003e 0:\n","        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n","    return (subplot[0], subplot[1], subplot[2]+1)\n","\n","def display_batch_of_images(databatch, predictions=None):\n","    \"\"\"This will work with:\n","    display_batch_of_images(images)\n","    display_batch_of_images(images, predictions)\n","    display_batch_of_images((images, labels))\n","    display_batch_of_images((images, labels), predictions)\n","    \"\"\"\n","    # data\n","    images, labels = batch_to_numpy_images_and_labels(databatch)\n","    if labels is None:\n","        labels = [None for _ in enumerate(images)]\n","\n","    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n","    rows = int(math.sqrt(len(images)))\n","    cols = len(images)//rows\n","\n","    # size and spacing\n","    FIGSIZE = 13.0\n","    SPACING = 0.1\n","    subplot=(rows,cols,1)\n","    if rows \u003c cols:\n","        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n","    else:\n","        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n","\n","    # display\n","    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n","        title = '' if label is None else class_dict[label]\n","        correct = True\n","        if predictions is not None:\n","            title, correct = title_from_label_and_target(predictions[i], label)\n","        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n","        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n","\n","    #layout\n","    plt.tight_layout()\n","    if label is None and predictions is None:\n","        plt.subplots_adjust(wspace=0, hspace=0)\n","    else:\n","        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n","    plt.show()\n","\n","def display_confusion_matrix(cmat, score, precision, recall):\n","    plt.figure(figsize=(15,15))\n","    ax = plt.gca()\n","    ax.matshow(cmat, cmap='Reds')\n","    ax.set_xticks(range(len(class_dict)))\n","    ax.set_xticklabels(class_dict, fontdict={'fontsize': 7})\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n","    ax.set_yticks(range(len(class_dict)))\n","    ax.set_yticklabels(class_dict, fontdict={'fontsize': 7})\n","    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n","    titlestring = \"\"\n","    if score is not None:\n","        titlestring += 'f1 = {:.3f} '.format(score)\n","    if precision is not None:\n","        titlestring += '\\nprecision = {:.3f} '.format(precision)\n","    if recall is not None:\n","        titlestring += '\\nrecall = {:.3f} '.format(recall)\n","    if titlestring != \"\":\n","        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n","    plt.show()\n","\n","def display_training_curves(training, validation, title, subplot):\n","    if subplot%10==1: # set up the subplots on the first call\n","        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n","        plt.tight_layout()\n","    ax = plt.subplot(subplot)\n","    ax.set_facecolor('#F8F8F8')\n","    ax.plot(training)\n","    ax.plot(validation)\n","    ax.set_title(f'model {title}')\n","    ax.set_ylabel(title)\n","    #ax.set_ylim(0.28,1.05)\n","    ax.set_xlabel('epoch')\n","    ax.legend(['train', 'valid.'])"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1696379127837,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"8ynfISf3No7z"},"outputs":[],"source":["def decode_image(image_data):\n","    image = tf.image.decode_jpeg(image_data, channels=3)  # image format uint8 [0,255]\n","    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n","    return image\n","\n","\n","def read_labeled_tfrecord(example):\n","    feature_description = {\n","        'image': tf.io.FixedLenFeature([], tf.string),\n","        'dataset': tf.io.FixedLenFeature([], tf.int64),\n","        'set': tf.io.FixedLenFeature([], tf.string),\n","        'longitude': tf.io.FixedLenFeature([], tf.float32),\n","        'latitude': tf.io.FixedLenFeature([], tf.float32),\n","        'norm_date': tf.io.FixedLenFeature([], tf.float32),\n","        'class_priors': tf.io.FixedLenFeature([], tf.float32),\n","        'class_id': tf.io.FixedLenFeature([], tf.int64),\n","    }\n","    example = tf.io.parse_single_example(example, feature_description)\n","    image = decode_image(example['image'])\n","    label = tf.cast(example['class_id'], tf.int32)\n","    return image, label\n","\n","\n","def load_dataset(filenames, labeled=True, ordered=False):\n","    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n","    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n","\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False # disable order, increase speed\n","\n","    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n","    dataset = dataset.cache()\n","    dataset = dataset.repeat()\n","    dataset = dataset.shuffle(2048)\n","    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls=AUTO) # if labeled else read_unlabeled_tfrecord\n","    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n","    return dataset\n","\n","def data_augment(image, label):\n","    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n","    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n","    # of the TPU while the TPU itself is computing gradients.\n","    # image = tf.image.random_flip_left_right(image)\n","    #image = tf.image.random_saturation(image, 0, 2)\n","    return image, label\n","\n","def get_training_dataset():\n","    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n","    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n","     # the training dataset must repeat for several epochs\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n","    return dataset\n","\n","def get_validation_dataset(ordered=False):\n","    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n","    return dataset\n","\n","# def get_test_dataset(ordered=False):\n","#     dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n","#     dataset = dataset.batch(BATCH_SIZE)\n","#     dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n","#     return dataset\n","\n","def count_data_items(filenames):\n","    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n","    return np.sum(n)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1696379127838,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"_T0iLwTwNo71","outputId":"491063d7-be0f-41f3-c18b-8802742830f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset: 96912 training images, 4373 validation images\n"]}],"source":["NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n","NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n","# NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n","STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n","VALIDATION_STEPS = -(-NUM_VALIDATION_IMAGES // BATCH_SIZE) # The \"-(-//)\" trick rounds up instead of down :-)\n","# TEST_STEPS = -(-NUM_TEST_IMAGES // BATCH_SIZE)             # The \"-(-//)\" trick rounds up instead of down :-)\n","print(\n","    f'Dataset: {NUM_TRAINING_IMAGES} training images, {NUM_VALIDATION_IMAGES} validation images'\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1696379127838,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"QPselnWIqKjA","outputId":"e8850f4b-e396-4346-8f05-704ea91afafa"},"outputs":[{"data":{"text/plain":["1514"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["STEPS_PER_EPOCH"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5430,"status":"ok","timestamp":1696379133501,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"cC5l84OONo73","outputId":"883de9a7-ffd2-432d-d6af-4a7d585afc8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data shapes:\n","(64, 224, 224, 3) (64,)\n","(64, 224, 224, 3) (64,)\n","(64, 224, 224, 3) (64,)\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: \u003cfunction Executor.__del__ at 0x780bbce02170\u003e\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n","    self.wait()\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n","    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n","tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n"]},{"name":"stdout","output_type":"stream","text":["Training data label examples: [104 274 309 ... 440 242  90]\n","Validation data shapes:\n","(64, 224, 224, 3) (64,)\n","(64, 224, 224, 3) (64,)\n","(64, 224, 224, 3) (64,)\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: \u003cfunction Executor.__del__ at 0x780bbce02170\u003e\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n","    self.wait()\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n","    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n","tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n"]},{"name":"stdout","output_type":"stream","text":["Validation data label examples: [ 73 182 359 ... 326 198  63]\n"]}],"source":["# data dump\n","print(\"Training data shapes:\")\n","for image, label in get_training_dataset().take(3):\n","    print(image.numpy().shape, label.numpy().shape)\n","print(\"Training data label examples:\", label.numpy())\n","print(\"Validation data shapes:\")\n","for image, label in get_validation_dataset().take(3):\n","    print(image.numpy().shape, label.numpy().shape)\n","print(\"Validation data label examples:\", label.numpy())\n","# print(\"Test data shapes:\")\n","# for image, idnum in get_test_dataset().take(3):\n","#     print(image.numpy().shape, idnum.numpy().shape)\n","# print(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1696379133502,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"SYJ_luSVNo74"},"outputs":[],"source":["# Peek at training data\n","training_dataset = get_training_dataset()\n","training_dataset = training_dataset.unbatch().batch(20)\n","train_batch = iter(training_dataset)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":893,"output_embedded_package_id":"1pDO7JhbVWAd-aVasLOOB31H-R3EQWhPM"},"executionInfo":{"elapsed":4470,"status":"ok","timestamp":1696379137957,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"LvzhBMQ_No75","outputId":"b6e6ffe0-0327-4f89-b829-ee947550b428"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["# run this cell again for next set of images\n","display_batch_of_images(next(train_batch))"]},{"cell_type":"markdown","metadata":{"id":"K1_Bez6dNo76"},"source":["you can select from these models:\n","- swin_tiny_224\n","- swin_small_224\n","- swin_base_224\n","- swin_base_384\n","- swin_large_224\n","- swin_large_384"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60922,"status":"ok","timestamp":1696379198868,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"rPcaVRUTNo76","outputId":"bae8b7eb-3a81-4820-fb2c-736a745d9d4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://github.com/rishigami/Swin-Transformer-TF/releases/download/v0.1-tf-swin-weights/swin_large_224.tgz\n","722592300/722592300 [==============================] - 10s 0us/step\n","Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lambda (Lambda)             (None, 224, 224, 3)       0         \n","                                                                 \n"," swin_large_224 (SwinTransfo  (None, 1536)             195331616 \n"," rmerModel)                                                      \n","                                                                 \n"," dense (Dense)               (None, 467)               717779    \n","                                                                 \n","=================================================================\n","Total params: 196,049,395\n","Trainable params: 195,713,255\n","Non-trainable params: 336,140\n","_________________________________________________________________\n"]}],"source":["with strategy.scope():\n","    img_adjust_layer = tf.keras.layers.Lambda(lambda data: tf.keras.applications.imagenet_utils.preprocess_input(tf.cast(data, tf.float32), mode=\"torch\"), input_shape=[*IMAGE_SIZE, 3])\n","    pretrained_model = SwinTransformer('swin_large_224', num_classes=len(class_dict), include_top=False, pretrained=True, use_tpu=True)\n","\n","    model = tf.keras.Sequential([\n","        img_adjust_layer,\n","        pretrained_model,\n","        tf.keras.layers.Dense(len(class_dict), activation='softmax')\n","    ])\n","\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5, epsilon=1e-8),\n","    loss = 'sparse_categorical_crossentropy',\n","    metrics=['sparse_categorical_accuracy']\n",")\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"fmM3Sf5ONo77"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/12\n","1514/1514 [==============================] - 728s 380ms/step - loss: 2.9240 - sparse_categorical_accuracy: 0.4153 - val_loss: 1.6093 - val_sparse_categorical_accuracy: 0.6327\n","Epoch 2/12\n","1514/1514 [==============================] - 547s 361ms/step - loss: 1.1464 - sparse_categorical_accuracy: 0.7179 - val_loss: 1.1325 - val_sparse_categorical_accuracy: 0.7095\n","Epoch 3/12\n"," 229/1514 [===\u003e..........................] - ETA: 7:37 - loss: 0.9189 - sparse_categorical_accuracy: 0.7672"]}],"source":["history = model.fit(get_training_dataset(), steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS,\n","                    validation_data=get_validation_dataset(), validation_steps=VALIDATION_STEPS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qfCXrWuFNo77"},"outputs":[],"source":["display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 211)\n","display_training_curves(history.history['sparse_categorical_accuracy'], history.history['val_sparse_categorical_accuracy'], 'accuracy', 212)"]}],"metadata":{"accelerator":"TPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}