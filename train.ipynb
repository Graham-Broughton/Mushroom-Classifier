{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from src.model_creation import get_train_dataset\n",
    "from src.model_creation import neural_net\n",
    "from src.visualization import plot_history\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load config file\n",
    "with open('model_config.yaml') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define learning rate function\n",
    "def lr_scheduler_fn(epoch):\n",
    "    return config['INITIAL_LEARNING_RATE'] * \\\n",
    "           tf.math.pow(config['LR_DECAY_FACTOR'], epoch//config['EPOCHS_PER_LR_DECAY'])\n",
    "\n",
    "#### define callbacks\n",
    "callbacks = [\n",
    "            tf.keras.callbacks.LearningRateScheduler(\n",
    "            lr_scheduler_fn,\n",
    "            verbose=1\n",
    "),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='loss', patience=3\n",
    "),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model():\n",
    "    if TPU:\n",
    "        resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "        tf.config.experimental_connect_to_cluster(resolver)\n",
    "        # This is the TPU initialization code that has to be at the beginning.\n",
    "        tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "        print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "        strategy = tf.distribute.TPUStrategy(resolver)\n",
    "    else:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "\n",
    "    (train_ds, num_train_examples) = get_train_dataset.make_dataset(\n",
    "        config[\"TRAINING_DATA\"],\n",
    "        label_column_name=config[\"LABEL_COLUMN_NAME\"],\n",
    "        image_column_name=config[\"IMAGE_COLUMN_NAME\"],\n",
    "        image_size=config[\"IMAGE_SIZE\"],\n",
    "        batch_size=config[\"BATCH_SIZE\"],\n",
    "        repeat_forever=True,\n",
    "        augment=True\n",
    "    )    \n",
    "    (val_ds, num_val_examples) = get_train_dataset.make_dataset(\n",
    "        config[\"VAL_DATA\"],\n",
    "        label_column_name=config[\"LABEL_COLUMN_NAME\"],\n",
    "        image_column_name=config[\"IMAGE_COLUMN_NAME\"],\n",
    "        image_size=config[\"IMAGE_SIZE\"],\n",
    "        batch_size=config[\"BATCH_SIZE\"],\n",
    "        repeat_forever=True,\n",
    "        augment=False\n",
    "    )\n",
    "\n",
    "    with strategy.scope():\n",
    "        # create optimizer for neural network\n",
    "        optimizer = keras.optimizers.RMSprop(\n",
    "            lr=config[\"INITIAL_LEARNING_RATE\"],\n",
    "            rho=config[\"RMSPROP_RHO\"],\n",
    "            momentum=config[\"RMSPROP_MOMENTUM\"],\n",
    "            epsilon=config[\"RMSPROP_EPSILON\"]\n",
    "        )\n",
    "\n",
    "        # create neural network\n",
    "        model = nets.make_neural_network(\n",
    "            base_arch_name = \"effecientnetv2l\",\n",
    "            weights = config[\"PRETRAINED_MODEL\"],\n",
    "            image_size = config[\"IMAGE_SIZE\"],\n",
    "            dropout_pct = config[\"DROPOUT_PCT\"],\n",
    "            n_classes = config[\"NUM_CLASSES\"],\n",
    "            input_dtype = tf.float32,\n",
    "            train_full_network = True\n",
    "        )\n",
    "\n",
    "        # load pretrained model\n",
    "        if config[\"PRETRAINED_MODEL\"] != \"imagenet\" and os.path.exists(config[\"PRETRAINED_MODEL\"]):\n",
    "            model.load_weights(config[\"PRETRAINED_MODEL\"])\n",
    "\n",
    "        if model is None:\n",
    "            print(\"No model to train.\")\n",
    "            return\n",
    "\n",
    "        # compile the network for training\n",
    "        model.compile(\n",
    "            loss=config['LOSS'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=[\n",
    "                \"accuracy\", \n",
    "                tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3 accuracy\"),\n",
    "                tf.keras.metrics.TopKCategoricalAccuracy(k=10, name=\"top10 accuracy\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        STEPS_PER_EPOCH = np.ceil(num_train_examples/config[\"BATCH_SIZE\"])\n",
    "        VAL_STEPS = np.ceil(num_val_examples/config[\"BATCH_SIZE\"])\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            validation_steps=VAL_STEPS,\n",
    "            epochs=config[\"NUM_EPOCHS\"],\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"time elapsed during fit: {:.1f}\".format(end-start))\n",
    "        print(history.history)\n",
    "        model.save(config[\"FINAL_SAVE_DIR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history.plot_history(accuracy)\n",
    "plot_history.plot_history(loss)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
