{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 02:04:45.804816: I tensorflow/compiler/xla/stream_executor/tpu/tpu_initializer_helper.cc:242] Libtpu path is: libtpu.so\n",
      "D1028 02:04:45.957949690   76915 config.cc:175]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\n",
      "D1028 02:04:45.957971562   76915 config.cc:175]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\n",
      "D1028 02:04:45.957976735   76915 config.cc:175]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\n",
      "D1028 02:04:45.957980979   76915 config.cc:175]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\n",
      "D1028 02:04:45.957985248   76915 config.cc:175]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\n",
      "D1028 02:04:45.957989468   76915 config.cc:175]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\n",
      "D1028 02:04:45.957993730   76915 config.cc:175]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\n",
      "D1028 02:04:45.957998085   76915 config.cc:175]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\n",
      "D1028 02:04:45.958002347   76915 config.cc:175]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\n",
      "D1028 02:04:45.958006705   76915 config.cc:175]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\n",
      "D1028 02:04:45.958010953   76915 config.cc:175]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\n",
      "D1028 02:04:45.958015083   76915 config.cc:175]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\n",
      "D1028 02:04:45.958019344   76915 config.cc:175]                        gRPC EXPERIMENT schedule_cancellation_over_write    OFF (default:OFF)\n",
      "D1028 02:04:45.958023512   76915 config.cc:175]                        gRPC EXPERIMENT trace_record_callops                OFF (default:OFF)\n",
      "D1028 02:04:45.958027697   76915 config.cc:175]                        gRPC EXPERIMENT event_engine_dns                    OFF (default:OFF)\n",
      "D1028 02:04:45.958031841   76915 config.cc:175]                        gRPC EXPERIMENT work_stealing                       OFF (default:OFF)\n",
      "D1028 02:04:45.958036103   76915 config.cc:175]                        gRPC EXPERIMENT client_privacy                      ON  (default:ON)\n",
      "D1028 02:04:45.958040208   76915 config.cc:175]                        gRPC EXPERIMENT canary_client_privacy               ON  (default:ON)\n",
      "D1028 02:04:45.958044340   76915 config.cc:175]                        gRPC EXPERIMENT server_privacy                      ON  (default:ON)\n",
      "D1028 02:04:45.958048489   76915 config.cc:175]                        gRPC EXPERIMENT unique_metadata_strings             OFF (default:OFF)\n",
      "D1028 02:04:45.958052605   76915 config.cc:175]                        gRPC EXPERIMENT keepalive_fix                       OFF (default:OFF)\n",
      "D1028 02:04:45.958056858   76915 config.cc:175]                        gRPC EXPERIMENT keepalive_server_fix                ON  (default:ON)\n",
      "D1028 02:04:45.958061014   76915 config.cc:175]                        gRPC EXPERIMENT promise_based_google_auth_filter    ON  (default:ON)\n",
      "D1028 02:04:45.958065231   76915 config.cc:175]                        gRPC EXPERIMENT promise_based_client_bwe_delegation OFF (default:OFF)\n",
      "D1028 02:04:45.958069392   76915 config.cc:175]                        gRPC EXPERIMENT promise_based_server_bwe_delegation OFF (default:OFF)\n",
      "D1028 02:04:45.958073508   76915 config.cc:175]                        gRPC EXPERIMENT oss_binary_logging                  OFF (default:OFF)\n",
      "D1028 02:04:45.958077632   76915 config.cc:175]                        gRPC EXPERIMENT loas_prefer_rekey_next_protocol     OFF (default:OFF)\n",
      "I1028 02:04:45.958300996   76915 ev_epoll1_linux.cc:123]               grpc epoll fd: 80\n",
      "D1028 02:04:45.958318488   76915 ev_posix.cc:113]                      Using polling engine: epoll1\n",
      "D1028 02:04:45.958649130   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"priority_experimental\"\n",
      "D1028 02:04:45.958658651   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"outlier_detection_experimental\"\n",
      "D1028 02:04:45.958668519   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"weighted_target_experimental\"\n",
      "D1028 02:04:45.958678802   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"pick_first\"\n",
      "D1028 02:04:45.958684100   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"round_robin\"\n",
      "D1028 02:04:45.958689192   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"weighted_round_robin\"\n",
      "D1028 02:04:45.958712837   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"grpclb\"\n",
      "D1028 02:04:45.958732143   76915 dns_resolver_plugin.cc:44]            Using ares dns resolver\n",
      "D1028 02:04:45.958752571   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"rls_experimental\"\n",
      "D1028 02:04:45.958795450   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"xds_cluster_manager_experimental\"\n",
      "D1028 02:04:45.958801534   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"xds_cluster_impl_experimental\"\n",
      "D1028 02:04:45.958806853   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"cds_experimental\"\n",
      "D1028 02:04:45.958812314   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\n",
      "D1028 02:04:45.958817288   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"xds_override_host_experimental\"\n",
      "D1028 02:04:45.958823135   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"xds_wrr_locality_experimental\"\n",
      "D1028 02:04:45.958828510   76915 lb_policy_registry.cc:47]             registering LB policy factory for \"ring_hash_experimental\"\n",
      "D1028 02:04:45.958833832   76915 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\n",
      "I1028 02:04:45.959838923   76915 ev_epoll1_linux.cc:360]               grpc epoll fd: 82\n",
      "I1028 02:04:45.986127370   76915 socket_utils_common_posix.cc:366]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\n",
      "2023-10-28 02:04:46.030012: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import src.training as tr_fn\n",
    "from loguru import logger\n",
    "from config import CFG, GCFG\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "CFG2 = GCFG()\n",
    "class_dict = pickle.load(open('src/class_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image_data, CFG):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)  # image format uint8 [0,255]\n",
    "    image = tf.reshape(image, [*CFG.IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(CFG, example):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'dataset': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'longitude': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'latitude': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'norm_date': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'class_priors': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'class_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    image = decode_image(example['image'], CFG)\n",
    "    label = tf.cast(example['class_id'], tf.int32)\n",
    "    return image, label\n",
    "\n",
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transform matrix which transforms indices\n",
    "\n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.0\n",
    "    shear = math.pi * shear / 180.0\n",
    "\n",
    "    def get_3x3_mat(lst):\n",
    "        return tf.reshape(tf.concat([lst], axis=0), [3, 3])\n",
    "\n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1], dtype='float32')\n",
    "    zero = tf.constant([0], dtype='float32')\n",
    "\n",
    "    rotation_matrix = get_3x3_mat([c1, s1, zero, -s1, c1, zero, zero, zero, one])\n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "\n",
    "    shear_matrix = get_3x3_mat([one, s2, zero, zero, c2, zero, zero, zero, one])\n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = get_3x3_mat([one / height_zoom, zero, zero, zero, one / width_zoom, zero, zero, zero, one])\n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = get_3x3_mat([one, zero, height_shift, zero, one, width_shift, zero, zero, one])\n",
    "\n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\n",
    "\n",
    "\n",
    "def transform(image, CFG):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    DIM = CFG.IMAGE_SIZE[0]\n",
    "    XDIM = DIM % 2  # fix for size 331   \n",
    "\n",
    "    rot = CFG.ROT_ * tf.random.normal([1], dtype='float32')\n",
    "    shr = CFG.SHR_ * tf.random.normal([1], dtype='float32')\n",
    "    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / CFG.HZOOM_\n",
    "    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / CFG.WZOOM_\n",
    "    h_shift = CFG.HSHIFT_ * tf.random.normal([1], dtype='float32')\n",
    "    w_shift = CFG.WSHIFT_ * tf.random.normal([1], dtype='float32')\n",
    "\n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot, shr, h_zoom, w_zoom, h_shift, w_shift)\n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat(tf.range(DIM // 2, -DIM // 2, -1), DIM)\n",
    "    y = tf.tile(tf.range(-DIM // 2, DIM // 2), [DIM])\n",
    "    z = tf.ones([DIM * DIM], dtype='int32')\n",
    "    idx = tf.stack([x, y, z])\n",
    "\n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n",
    "    idx2 = K.cast(idx2, dtype='int32')\n",
    "    idx2 = K.clip(idx2, -DIM // 2 + XDIM + 1, DIM // 2)\n",
    "\n",
    "    # FIND ORIGIN PIXEL VALUES\n",
    "    idx3 = tf.stack([DIM // 2 - idx2[0,], DIM // 2 - 1 + idx2[1,]])\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "\n",
    "    return tf.reshape(d, [DIM, DIM, 3])\n",
    "\n",
    "\n",
    "def prepare_image(img, CFG, augment=True, dim=256):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "    if augment:\n",
    "        img = transform(img, CFG)\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        # img = tf.image.random_hue(img, 0.01)\n",
    "        img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "\n",
    "    img = tf.reshape(img, [CFG.IMAGE_SIZE[0], CFG.IMAGE_SIZE[0], 3])\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_dataset(\n",
    "    files, CFG, augment=False, shuffle=False, repeat=False, labeled=True, batch_size=16, dim=256\n",
    "    ):\n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "    ds = ds.cache()\n",
    "\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1024 * 8)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "\n",
    "    if labeled:\n",
    "        ds = ds.map(lambda example: read_labeled_tfrecord(CFG, example), num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda example: read_unlabeled_tfrecord(example), num_parallel_calls=AUTO)\n",
    "\n",
    "    ds = ds.map(\n",
    "        lambda img, imgname_or_label: (prepare_image(\n",
    "            img, CFG, augment=augment, dim=dim), imgname_or_label), num_parallel_calls=AUTO\n",
    "    )\n",
    "\n",
    "    ds = ds.batch(batch_size * CFG.REPLICAS)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(model, fold, files_train, files_valid, CFG):\n",
    "    logger.info(\"Training...\")\n",
    "    history = model.fit(\n",
    "        get_dataset(files_train, CFG),\n",
    "        epochs=CFG.EPOCHS,\n",
    "        callbacks=tr_fn.make_callbacks(CFG),\n",
    "        steps_per_epoch=CFG.STEPS_PER_EPOCH,\n",
    "        validation_data=get_dataset(files_valid, CFG),  # class_weight = {0:1,1:2},\n",
    "        verbose=CFG.VERBOSE,\n",
    "    )\n",
    "    return history\n",
    "\n",
    "def get_gcs_path(image_size):\n",
    "    GCS_PATH_SELECT = {\n",
    "        192: f\"{CFG2.GCS_REPO}/tfrecords-jpeg-192x192\",\n",
    "        224: f\"{CFG2.GCS_REPO}/tfrecords-jpeg-224x224v2\",\n",
    "        384: f\"{CFG2.GCS_REPO}/tfrecords-jpeg-384x384\",\n",
    "        512: f\"{CFG2.GCS_REPO}/tfrecords-jpeg-512x512\",\n",
    "    }\n",
    "    GCS_PATH = GCS_PATH_SELECT[image_size]    \n",
    "    return GCS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 02:04:58.898527: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5642a0268de0 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-28 02:04:58.898567: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TPU, 2a886c8\n",
      "2023-10-28 02:04:58.898579: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): TPU, 2a886c8\n",
      "2023-10-28 02:04:58.898589: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): TPU, 2a886c8\n",
      "2023-10-28 02:04:58.898599: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): TPU, 2a886c8\n",
      "2023-10-28 02:04:58.898609: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): TPU, 2a886c8\n",
      "2023-10-28 02:04:58.898619: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): TPU, 2a886c8\n",
      "2023-10-28 02:04:58.898629: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): TPU, 2a886c8\n",
      "2023-10-28 02:04:58.898639: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (7): TPU, 2a886c8\n",
      "2023-10-28 02:04:58.898808: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.898874: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.898932: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.898995: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.899058: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.899230: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.899295: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.899359: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.899421: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.899484: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.899672: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.899754: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.899843: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.899919: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.900001: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.900218: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.900295: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.900371: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.900452: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.900638: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.900909: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.901004: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.901089: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.901282: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.901382: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.901567: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.901631: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.901685: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.901753: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.901811: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.902058: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.902116: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.902193: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.902258: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.902322: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.902521: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.902587: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.902649: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.902722: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-28 02:04:58.902779: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n",
      "Number of accelerators:  8\n"
     ]
    }
   ],
   "source": [
    "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n",
    "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
    "\n",
    "CFG2.REPLICAS = strategy.num_replicas_in_sync\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "#### FOLD 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'CFG' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/broug/Mushroom-Classifier/training/test.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmy-tpu.us-central1-a.mush-classifier/home/broug/Mushroom-Classifier/training/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m CFG2\u001b[39m.\u001b[39mNUM_TRAINING_IMAGES \u001b[39m=\u001b[39m tr_fn\u001b[39m.\u001b[39mcount_data_items(files_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmy-tpu.us-central1-a.mush-classifier/home/broug/Mushroom-Classifier/training/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m CFG2\u001b[39m.\u001b[39mNUM_VALIDATION_IMAGES \u001b[39m=\u001b[39m tr_fn\u001b[39m.\u001b[39mcount_data_items(files_valid)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmy-tpu.us-central1-a.mush-classifier/home/broug/Mushroom-Classifier/training/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m CFG \u001b[39m=\u001b[39m CFG(REPLICAS\u001b[39m=\u001b[39;49mCFG2\u001b[39m.\u001b[39;49mREPLICAS, NUM_TRAINING_IMAGES\u001b[39m=\u001b[39;49mCFG2\u001b[39m.\u001b[39;49mNUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES\u001b[39m=\u001b[39;49mCFG2\u001b[39m.\u001b[39;49mNUM_VALIDATION_IMAGES)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmy-tpu.us-central1-a.mush-classifier/home/broug/Mushroom-Classifier/training/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmy-tpu.us-central1-a.mush-classifier/home/broug/Mushroom-Classifier/training/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m# Image Size \u001b[39m\u001b[39m{\u001b[39;00mCFG2\u001b[39m.\u001b[39mIMAGE_SIZE\u001b[39m}\u001b[39;00m\u001b[39m with Model \u001b[39m\u001b[39m{\u001b[39;00mCFG2\u001b[39m.\u001b[39mMODEL\u001b[39m}\u001b[39;00m\u001b[39m and batch_sz \u001b[39m\u001b[39m{\u001b[39;00mCFG2\u001b[39m.\u001b[39mBASE_BATCH_SIZE \u001b[39m*\u001b[39m CFG2\u001b[39m.\u001b[39mREPLICAS\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmy-tpu.us-central1-a.mush-classifier/home/broug/Mushroom-Classifier/training/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmy-tpu.us-central1-a.mush-classifier/home/broug/Mushroom-Classifier/training/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mBuild & Compile Model...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'CFG' object is not callable"
     ]
    }
   ],
   "source": [
    "GCS_PATH = get_gcs_path(CFG2.IMAGE_SIZE[0])\n",
    "skf = KFold(n_splits=CFG2.FOLDS, shuffle=True, random_state=CFG2.SEED)\n",
    "oof_pred = []\n",
    "oof_tar = []\n",
    "oof_val = []\n",
    "oof_names = []\n",
    "oof_folds = []\n",
    "\n",
    "for fold, (idxT, idxV) in enumerate(skf.split(np.arange(107))):\n",
    "    # DISPLAY FOLD INFO\n",
    "    print(\"#\" * 25)\n",
    "    print(\"#### FOLD\", fold + 1)\n",
    "\n",
    "    files_train = tf.io.gfile.glob([f\"{GCS_PATH}/train{x:02d}*.tfrec\" for x in idxT])\n",
    "    files_valid = tf.io.gfile.glob(f\"{GCS_PATH}/train{x:02d}*.tfrec\" for x in idxV)\n",
    "    files_test = tf.io.gfile.glob(f\"{GCS_PATH}/val*.tfrec\")\n",
    "\n",
    "    CFG2.NUM_TRAINING_IMAGES = tr_fn.count_data_items(files_train)\n",
    "    CFG2.NUM_VALIDATION_IMAGES = tr_fn.count_data_items(files_valid)\n",
    "\n",
    "    CFG = CFG(REPLICAS=CFG2.REPLICAS, NUM_TRAINING_IMAGES=CFG2.NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES=CFG2.NUM_VALIDATION_IMAGES)\n",
    "\n",
    "    logger.debug(\n",
    "        f\"# Image Size {CFG2.IMAGE_SIZE} with Model {CFG2.MODEL} and batch_sz {CFG2.BASE_BATCH_SIZE * CFG2.REPLICAS}\"\n",
    "    )\n",
    "\n",
    "    logger.info(\"Build & Compile Model...\")\n",
    "    K.clear_session()\n",
    "    with strategy.scope():\n",
    "        model = tr_fn.create_model(CFG, class_dict)\n",
    "        opt = tr_fn.create_optimizer(CFG)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "        top3_acc = tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "            k=3, name='sparse_top_3_categorical_accuracy'\n",
    "        )\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=['sparse_categorical_accuracy', top3_acc])\n",
    "\n",
    "    logger.info(\"Training Model...\")\n",
    "    # TRAIN\n",
    "    history = get_history(model, fold, files_train, files_valid, CFG)\n",
    "\n",
    "    # PREDICT OOF USING TTA\n",
    "    logger.info(\"Predicting OOF with TTA...\")\n",
    "    ds_valid = get_dataset(files_valid, CFG),\n",
    "    ct_valid = tr_fn.count_data_items(files_valid)\n",
    "    STEPS = CFG.TTA * ct_valid / CFG.BATCH_SIZES / 4 / CFG.REPLICAS\n",
    "    pred = model.predict(ds_valid, steps=STEPS, verbose=CFG.VERBOSE)[\n",
    "        : CFG.TTA * ct_valid,\n",
    "    ]\n",
    "    oof_pred.append(np.mean(pred.reshape((ct_valid, CFG.TTA), order=\"F\"), axis=1))\n",
    "    # oof_pred.append(model.predict(get_dataset(files_valid,dim=CFG.IMG_SIZES),verbose=1))\n",
    "\n",
    "    # GET OOF TARGETS AND NAMES\n",
    "    ds_valid = get_dataset(\n",
    "        files_valid,\n",
    "        CFG,\n",
    "        augment=False,\n",
    "        repeat=False,\n",
    "        dim=CFG.IMG_SIZES,\n",
    "        labeled=True,\n",
    "        return_image_names=True,\n",
    "    )\n",
    "    oof_tar.append(\n",
    "        np.array([target.numpy() for img, target in iter(ds_valid.unbatch())])\n",
    "    )\n",
    "    oof_folds.append(np.ones_like(oof_tar[-1], dtype=\"int8\") * fold)\n",
    "    ds = get_dataset(\n",
    "        files_valid,\n",
    "        CFG,\n",
    "        augment=False,\n",
    "        repeat=False,\n",
    "        dim=CFG.IMG_SIZES,\n",
    "        labeled=False,\n",
    "        return_image_names=True,\n",
    "    )\n",
    "    oof_names.append(\n",
    "        np.array(\n",
    "            [\n",
    "                img_name.numpy().decode(\"utf-8\")\n",
    "                for img, img_name in iter(ds.unbatch())\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # REPORT RESULTS\n",
    "    auc = roc_auc_score(oof_tar[-1], oof_pred[-1])\n",
    "    oof_val.append(np.max(history.history[\"val_auc\"]))\n",
    "    logger.info(\n",
    "        f\"#### FOLD {fold + 1} OOF AUC without TTA = {oof_val[-1]}, with TTA = {auc}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
