{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow==2.12.0 python_dotenv wandb tensorflow-addons==0.22.0 # tensorboard_plugin_profile==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1697361847933,
     "user": {
      "displayName": "graham broughton",
      "userId": "15728648374086258761"
     },
     "user_tz": 420
    },
    "id": "PKiDhRvyNwiw",
    "outputId": "166b32ab-cf89-4855-854e-283c05ec1158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/drive/MyDrive/Mushroom-Classifier'\n",
      "/home/broug/Desktop/Mushroom-Classifier/training\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1697361848140,
     "user": {
      "displayName": "graham broughton",
      "userId": "15728648374086258761"
     },
     "user_tz": 420
    },
    "id": "GEQKIS-h_JS2"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Mushroom-Classifier\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3230,
     "status": "ok",
     "timestamp": 1697361852221,
     "user": {
      "displayName": "graham broughton",
      "userId": "15728648374086258761"
     },
     "user_tz": 420
    },
    "id": "LfAu_aLnNo7l",
    "outputId": "9eb39522-b6f7-46bf-e0e8-74635f093a9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 13:09:51.653571: I tensorflow/compiler/xla/stream_executor/tpu/tpu_initializer_helper.cc:242] Libtpu path is: libtpu.so\n",
      "D1112 13:09:51.762660973   83890 config.cc:175]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\n",
      "D1112 13:09:51.762681117   83890 config.cc:175]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\n",
      "D1112 13:09:51.762685646   83890 config.cc:175]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\n",
      "D1112 13:09:51.762689146   83890 config.cc:175]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\n",
      "D1112 13:09:51.762693623   83890 config.cc:175]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\n",
      "D1112 13:09:51.762697499   83890 config.cc:175]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\n",
      "D1112 13:09:51.762701661   83890 config.cc:175]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\n",
      "D1112 13:09:51.762705422   83890 config.cc:175]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\n",
      "D1112 13:09:51.762708828   83890 config.cc:175]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\n",
      "D1112 13:09:51.762712081   83890 config.cc:175]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\n",
      "D1112 13:09:51.762716524   83890 config.cc:175]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\n",
      "D1112 13:09:51.762720217   83890 config.cc:175]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\n",
      "D1112 13:09:51.762723927   83890 config.cc:175]                        gRPC EXPERIMENT schedule_cancellation_over_write    OFF (default:OFF)\n",
      "D1112 13:09:51.762728031   83890 config.cc:175]                        gRPC EXPERIMENT trace_record_callops                OFF (default:OFF)\n",
      "D1112 13:09:51.762731504   83890 config.cc:175]                        gRPC EXPERIMENT event_engine_dns                    OFF (default:OFF)\n",
      "D1112 13:09:51.762734911   83890 config.cc:175]                        gRPC EXPERIMENT work_stealing                       OFF (default:OFF)\n",
      "D1112 13:09:51.762739142   83890 config.cc:175]                        gRPC EXPERIMENT client_privacy                      ON  (default:ON)\n",
      "D1112 13:09:51.762742640   83890 config.cc:175]                        gRPC EXPERIMENT canary_client_privacy               ON  (default:ON)\n",
      "D1112 13:09:51.762746800   83890 config.cc:175]                        gRPC EXPERIMENT server_privacy                      ON  (default:ON)\n",
      "D1112 13:09:51.762750195   83890 config.cc:175]                        gRPC EXPERIMENT unique_metadata_strings             OFF (default:OFF)\n",
      "D1112 13:09:51.762753737   83890 config.cc:175]                        gRPC EXPERIMENT keepalive_fix                       OFF (default:OFF)\n",
      "D1112 13:09:51.762757748   83890 config.cc:175]                        gRPC EXPERIMENT keepalive_server_fix                ON  (default:ON)\n",
      "D1112 13:09:51.762761137   83890 config.cc:175]                        gRPC EXPERIMENT promise_based_google_auth_filter    ON  (default:ON)\n",
      "D1112 13:09:51.762764627   83890 config.cc:175]                        gRPC EXPERIMENT promise_based_client_bwe_delegation OFF (default:OFF)\n",
      "D1112 13:09:51.762768575   83890 config.cc:175]                        gRPC EXPERIMENT promise_based_server_bwe_delegation OFF (default:OFF)\n",
      "D1112 13:09:51.762772008   83890 config.cc:175]                        gRPC EXPERIMENT oss_binary_logging                  OFF (default:OFF)\n",
      "D1112 13:09:51.762775426   83890 config.cc:175]                        gRPC EXPERIMENT loas_prefer_rekey_next_protocol     OFF (default:OFF)\n",
      "I1112 13:09:51.763045901   83890 ev_epoll1_linux.cc:123]               grpc epoll fd: 78\n",
      "D1112 13:09:51.763067824   83890 ev_posix.cc:113]                      Using polling engine: epoll1\n",
      "D1112 13:09:51.763417588   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"priority_experimental\"\n",
      "D1112 13:09:51.763427572   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"outlier_detection_experimental\"\n",
      "D1112 13:09:51.763437697   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"weighted_target_experimental\"\n",
      "D1112 13:09:51.763447883   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"pick_first\"\n",
      "D1112 13:09:51.763452924   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"round_robin\"\n",
      "D1112 13:09:51.763457970   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"weighted_round_robin\"\n",
      "D1112 13:09:51.763481567   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"grpclb\"\n",
      "D1112 13:09:51.763501205   83890 dns_resolver_plugin.cc:44]            Using ares dns resolver\n",
      "D1112 13:09:51.763523750   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"rls_experimental\"\n",
      "D1112 13:09:51.763555726   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"xds_cluster_manager_experimental\"\n",
      "D1112 13:09:51.763571156   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"xds_cluster_impl_experimental\"\n",
      "D1112 13:09:51.763577680   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"cds_experimental\"\n",
      "D1112 13:09:51.763583161   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\n",
      "D1112 13:09:51.763588248   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"xds_override_host_experimental\"\n",
      "D1112 13:09:51.763593790   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"xds_wrr_locality_experimental\"\n",
      "D1112 13:09:51.763599132   83890 lb_policy_registry.cc:47]             registering LB policy factory for \"ring_hash_experimental\"\n",
      "D1112 13:09:51.763604596   83890 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\n",
      "I1112 13:09:51.764589153   83890 ev_epoll1_linux.cc:360]               grpc epoll fd: 80\n",
      "I1112 13:09:51.790026943   83991 socket_utils_common_posix.cc:366]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\n",
      "2023-11-12 13:09:51.835360: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.14.0\n"
     ]
    }
   ],
   "source": [
    "import math, re, os, pickle\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Sequential\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.swintransformer import SwinTransformer\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback, WandbMetricsLogger, WandbEvalCallback\n",
    "from train_config import CFG\n",
    "\n",
    "print(f\"Tensorflow version {tf.__version__}\")\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "CFG = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(CFG.SEED)\n",
    "tf.random.set_seed(CFG.SEED)\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hardware\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "except ValueError:  # If TPU not found\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnHHCJk-No7v"
   },
   "source": [
    "## Visualization Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1697361918383,
     "user": {
      "displayName": "graham broughton",
      "userId": "15728648374086258761"
     },
     "user_tz": 420
    },
    "id": "yTKGP-V2No7x"
   },
   "outputs": [],
   "source": [
    "def batch_to_numpy_images_and_labels(data):\n",
    "    images, labels = data\n",
    "    numpy_images = images.numpy()\n",
    "    numpy_labels = labels.numpy()\n",
    "    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n",
    "        numpy_labels = [None for _ in enumerate(numpy_images)]\n",
    "    # If no labels, only image IDs, return None for labels (this is the case for test data)\n",
    "    return numpy_images, numpy_labels\n",
    "\n",
    "def title_from_label_and_target(label, correct_label):\n",
    "    if correct_label is None:\n",
    "        return class_dict[label], True\n",
    "    correct = (label == correct_label)\n",
    "    return \"{} [{}{}{}]\".format(class_dict[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n",
    "                                class_dict[correct_label] if not correct else ''), correct\n",
    "\n",
    "def display_one_flower(image, title, subplot, red=False, titlesize=16):\n",
    "    image = (image - image.min()) / (\n",
    "        image.max() - image.min()\n",
    "    )  # convert to [0, 1] for avoiding matplotlib warning\n",
    "    plt.subplot(*subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    if len(title) > 0:\n",
    "        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n",
    "    return (subplot[0], subplot[1], subplot[2]+1)\n",
    "\n",
    "def display_batch_of_images(databatch, predictions=None):\n",
    "    \"\"\"This will work with:\n",
    "    (images), (images, predictions), ((images, labels)), ((images, labels), predictions)\n",
    "    \"\"\"\n",
    "    # data\n",
    "    images, labels = batch_to_numpy_images_and_labels(databatch)\n",
    "    if labels is None:\n",
    "        labels = [None for _ in enumerate(images)]\n",
    "\n",
    "    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n",
    "    rows = int(math.sqrt(len(images)))\n",
    "    cols = len(images)//rows\n",
    "\n",
    "    # size and spacing\n",
    "    FIGSIZE = 13.0\n",
    "    SPACING = 0.1\n",
    "    subplot=(rows,cols,1)\n",
    "    if rows < cols:\n",
    "        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n",
    "    else:\n",
    "        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n",
    "\n",
    "    # display\n",
    "    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n",
    "        title = '' if label is None else class_dict[label]\n",
    "        correct = True\n",
    "        if predictions is not None:\n",
    "            title, correct = title_from_label_and_target(predictions[i], label)\n",
    "        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n",
    "        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n",
    "\n",
    "    #layout\n",
    "    plt.tight_layout()\n",
    "    if label is None and predictions is None:\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    else:\n",
    "        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n",
    "    plt.show()\n",
    "\n",
    "def display_confusion_matrix(cmat, score, precision, recall):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    ax = plt.gca()\n",
    "    ax.matshow(cmat, cmap='Reds')\n",
    "    ax.set_xticks(range(len(class_dict)))\n",
    "    ax.set_xticklabels(class_dict, fontdict={'fontsize': 7})\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n",
    "    ax.set_yticks(range(len(class_dict)))\n",
    "    ax.set_yticklabels(class_dict, fontdict={'fontsize': 7})\n",
    "    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    titlestring = \"\"\n",
    "    if score is not None:\n",
    "        titlestring += 'f1 = {:.3f} '.format(score)\n",
    "    if precision is not None:\n",
    "        titlestring += '\\nprecision = {:.3f} '.format(precision)\n",
    "    if recall is not None:\n",
    "        titlestring += '\\nrecall = {:.3f} '.format(recall)\n",
    "    if titlestring != \"\":\n",
    "        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n",
    "    plt.show()\n",
    "\n",
    "def display_training_curves(training, validation, title, subplot):\n",
    "    if subplot%10==1: # set up the subplots on the first call\n",
    "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
    "        plt.tight_layout()\n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.set_facecolor('#F8F8F8')\n",
    "    ax.plot(training)\n",
    "    ax.plot(validation)\n",
    "    ax.set_title(f'model {title}')\n",
    "    ax.set_ylabel(title)\n",
    "    #ax.set_ylim(0.28,1.05)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['train', 'valid.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 683,
     "status": "ok",
     "timestamp": 1697361919060,
     "user": {
      "displayName": "graham broughton",
      "userId": "15728648374086258761"
     },
     "user_tz": 420
    },
    "id": "8ynfISf3No7z"
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1))\n",
    "         for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "def decode_image(image_data, smallest_side, CFG):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)  # image format uint8 [0,255]\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, smallest_side, smallest_side)\n",
    "    image = tf.image.resize(image, size=CFG.RAW_SIZE, method=\"lanczos5\")\n",
    "    image = tf.image.random_crop(image, size=[*CFG.CROP_SIZE, 3])  #, method=\"lanczos5\"\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example, CFG):\n",
    "    feature_description = {\n",
    "        \"image/encoded\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image/id\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image/meta/width\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image/meta/height\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image/class/label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "\n",
    "    width = tf.cast(example['image/meta/width'], tf.int32)\n",
    "    height = tf.cast(example['image/meta/height'], tf.int32)\n",
    "    smallest_side = tf.minimum(width, height)\n",
    "\n",
    "    image = decode_image(example[\"image/encoded\"], smallest_side, CFG)\n",
    "    label = tf.cast(example[\"image/class/label\"], tf.int32)\n",
    "\n",
    "    return image, label\n",
    "    # id = tf.cast(example['image/id'], tf.string)\n",
    "    # return image, label, id\n",
    "\n",
    "def load_dataset(filenames, CFG):\n",
    "  # read from TFRecords. For optimal performance, read from multiple\n",
    "  # TFRecord files at once and set the option experimental_deterministic = False\n",
    "  # to allow order-altering optimizations.\n",
    "  option_no_order = tf.data.Options()\n",
    "  option_no_order.experimental_deterministic = False\n",
    "\n",
    "  dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
    "  dataset = dataset.with_options(option_no_order)\n",
    "\n",
    "  dataset = dataset.map(lambda x: read_labeled_tfrecord(x, CFG), num_parallel_calls=AUTO)\n",
    "  return dataset\n",
    "\n",
    "def basic_augment(image, prob_hflip=0.5, prob_vflip=0.5, prob_color_jitter=0.5, prob_rotate=0.5):\n",
    "    \"\"\"Apply various augmentations to an image.\n",
    "\n",
    "    Args:\n",
    "        image: The input image.\n",
    "        prob_hflip: Probability of applying horizontal flip.\n",
    "        prob_vflip:\n",
    "        prob_color_jitter: Probability of applying color jitter.\n",
    "        prob_rotate: Probability of applying rotation.\n",
    "\n",
    "    Returns:\n",
    "        Augmented image.\n",
    "    \"\"\"\n",
    "    # Horizontal Flip\n",
    "    if tf.random.uniform([]) < prob_hflip:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    if tf.random.uniform([]) < prob_vflip:\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "\n",
    "    # Color Jitter\n",
    "    if tf.random.uniform([]) < prob_color_jitter:\n",
    "        image = tf.image.random_brightness(image, max_delta=0.4)\n",
    "        image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n",
    "        image = tf.image.random_saturation(image, lower=0.7, upper=1.3)\n",
    "        image = tf.image.random_hue(image, max_delta=0.3)\n",
    "\n",
    "    # Rotation\n",
    "    if tf.random.uniform([]) < prob_rotate:\n",
    "        angles = tf.random.uniform([], -18, 18)\n",
    "        image = tfa.image.rotate(image, angles, fill_mode='reflect')\n",
    "    return image\n",
    "\n",
    "def random_masking(image, randmask_prob=0.5):\n",
    "    if tf.random.uniform([]) < randmask_prob:\n",
    "        original_shape = tf.shape(image)\n",
    "\n",
    "        count = tf.random.uniform([], 1, 11)\n",
    "\n",
    "        erase_size = tf.random.uniform([], 0.2, 0.5)\n",
    "        erase_size = tf.math.divide(erase_size, tf.math.sqrt(count))\n",
    "        erase_value = tf.random.uniform([], 0., 255.)\n",
    "\n",
    "        mask1 = int(erase_size * float(original_shape[0])) - (int(erase_size * float(original_shape[0])) % 2)\n",
    "        mask2 = int(erase_size * float(original_shape[1])) - (int(erase_size * float(original_shape[1])) % 2)\n",
    "        for k in tf.range(count):\n",
    "            image = tfa.image.random_cutout(\n",
    "                tf.expand_dims(image, axis=0),\n",
    "                mask_size=(mask1, mask2),\n",
    "                constant_values=erase_value\n",
    "            )\n",
    "            image = tf.squeeze(image, 0)\n",
    "    return image\n",
    "\n",
    "def augment(images, labels):\n",
    "    images = tf.map_fn(basic_augment, images)\n",
    "    images = tf.map_fn(random_masking, images)\n",
    "    return images, labels\n",
    "\n",
    "def get_batched_dataset(filenames, CFG, train=False):\n",
    "    dataset = load_dataset(filenames, CFG)\n",
    "    # dataset = dataset.cache() # This dataset fits in RAM\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(CFG.BATCH_SIZE, drop_remainder=True)\n",
    "    if train:\n",
    "        dataset = dataset.map(augment, num_parallel_calls=AUTO)\n",
    "        # dataset = dataset.shuffle(BATCH_SIZE * 10)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1697361919818,
     "user": {
      "displayName": "graham broughton",
      "userId": "15728648374086258761"
     },
     "user_tz": 420
    },
    "id": "_T0iLwTwNo71"
   },
   "outputs": [],
   "source": [
    "CFG.BATCH_SIZE = CFG.BASE_BATCH_SIZE * REPLICAS\n",
    "\n",
    "GCS_PATH_SELECT = {\n",
    "    192: f\"gs://{CFG.GCS_REPO}/tfrecords-jpeg-192x192\",\n",
    "    224: f\"gs://{CFG.GCS_REPO}/tfrecords-jpeg-224x224\",\n",
    "    331: f\"gs://{CFG.GCS_REPO}/tfrecords-jpeg-331x331\",\n",
    "    512: f\"gs://{CFG.GCS_REPO}/tfrecords-jpeg-512x512\",\n",
    "    None: f\"gs://{CFG.GCS_REPO}/tfrecords-jpeg-raw\",\n",
    "}\n",
    "GCS_PATH = GCS_PATH_SELECT[None]\n",
    "\n",
    "filenames = tf.io.gfile.glob(f\"{GCS_PATH}/train*.tfrec\")\n",
    "filenames, test_filenames = train_test_split(filenames, test_size=1, shuffle=True)\n",
    "training_filenames, validation_filenames = train_test_split(\n",
    "    filenames, test_size=0.15, shuffle=True\n",
    ")\n",
    "\n",
    "num_train = count_data_items(training_filenames)\n",
    "num_val = count_data_items(validation_filenames)\n",
    "num_test = count_data_items(test_filenames)\n",
    "\n",
    "validation_steps = num_val / CFG.BATCH_SIZE // REPLICAS\n",
    "steps_per_epoch = num_train / CFG.BATCH_SIZE // REPLICAS\n",
    "TOTAL_STEPS = int(steps_per_epoch * (CFG.EPOCHS - 1))\n",
    "\n",
    "class_dict = pickle.load(open(\"src/class_dict_NEW.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.DEBUG:\n",
    "    print(\"Training data shapes:\")\n",
    "    for (image, meta), label in get_batched_dataset(\n",
    "        training_filenames, CFG, train=True\n",
    "    ).take(3):\n",
    "        print(image.numpy().shape, label.numpy().shape)\n",
    "    print(\"Training data label examples:\", label.numpy())\n",
    "    print(\"Validation data shapes:\")\n",
    "    for (image, meta), label in get_batched_dataset(validation_filenames, CFG).take(3):\n",
    "        print(image.numpy().shape, label.numpy().shape)\n",
    "    print(\"Validation data label examples:\", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.DEBUG:\n",
    "    # Peek at training data\n",
    "    training_dataset = get_batched_dataset(training_filenames, CFG, train=True)\n",
    "    training_dataset = training_dataset.unbatch().batch(20)\n",
    "    train_batch = iter(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.DEBUG:\n",
    "    # run this cell again for next set of images\n",
    "    display_batch_of_images(next(train_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "cC5l84OONo73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 224, 224, 3) (256,)\n",
      "(256, 224, 224, 3) (256,)\n",
      "(256, 224, 224, 3) (256,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 13:39:16.484093: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data label examples: [100 215  58 ... 352 187  18]\n",
      "Validation data shapes:\n",
      "(256, 224, 224, 3) (256,)\n",
      "(256, 224, 224, 3) (256,)\n",
      "(256, 224, 224, 3) (256,)\n",
      "Validation data label examples: [  8 233 457 ... 208 206 197]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 13:39:17.991477: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    img_adjust_layer = layers.Lambda(lambda data: tf.keras.applications.imagenet_utils.preprocess_input(tf.cast(data, tf.float32), mode=\"torch\"), input_shape=[*CFG.CROP_SIZE, 3])\n",
    "    pretrained_model = SwinTransformer(CFG.MODEL, num_classes=len(class_dict), include_top=False, pretrained=True, use_tpu=True)\n",
    "\n",
    "    model = Sequential([\n",
    "        img_adjust_layer,\n",
    "        pretrained_model,\n",
    "    ])\n",
    "\n",
    "    # Assuming input_image is the input layer for model\n",
    "    input_image = layers.Input(shape=model.input_shape[1:])\n",
    "    model_output = model(input_image)\n",
    "    output = layers.Dense(len(class_dict), activation='softmax')(model_output)\n",
    "\n",
    "    # Create the final model\n",
    "    final_model = Model(inputs=input_image, outputs=output)\n",
    "\n",
    "    top3 = tf.keras.metrics.SparseTopKCategoricalAccuracy(3, name='top-3-accuracy')\n",
    "\n",
    "final_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5, epsilon=1e-8),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy', top3]\n",
    ")\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gCIJLIgW7tqS"
   },
   "outputs": [],
   "source": [
    "def get_lr_callback(batch_size=8, plot=False):\n",
    "    lr_start   = 0.000001\n",
    "    lr_max     = 0.00000030 * batch_size\n",
    "    lr_min     = 0.0000001\n",
    "    lr_ramp_ep = 5\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.9\n",
    "    CFG.LR_START, CFG.LR_MAX, CFG.LR_MIN, CFG.RAMPEP, CFG.DECAY = lr_start, lr_max, lr_min, lr_ramp_ep, lr_decay\n",
    "    \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "\n",
    "        elif CFG.SCHEDULER=='exp':\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "\n",
    "        elif CFG.SCHEDULER=='cosine':\n",
    "            decay_total_epochs = CFG.EPOCHS - lr_ramp_ep - lr_sus_ep + 3\n",
    "            decay_epoch_index = epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "            cosine_decay = 0.4 * (1 + math.cos(phase))\n",
    "            lr = (lr_max - lr_min) * cosine_decay + lr_min\n",
    "        \n",
    "        gc.collect()\n",
    "        return lr\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(np.arange(CFG.EPOCHS), [lrfn(epoch) for epoch in np.arange(CFG.EPOCHS)], marker='o')\n",
    "        plt.xlabel('epoch'); plt.ylabel('learning rate')\n",
    "        plt.title('Learning Rate Scheduler')\n",
    "        plt.show()\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback\n",
    "\n",
    "_=get_lr_callback(CFG.BATCH_SIZE, plot=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 735,
     "status": "ok",
     "timestamp": 1697362294835,
     "user": {
      "displayName": "graham broughton",
      "userId": "15728648374086258761"
     },
     "user_tz": 420
    },
    "id": "6V4wIMBH5xPK"
   },
   "outputs": [],
   "source": [
    "config = wandb.helper.parse_config(\n",
    "    CFG, include=('AUGMENT', 'BATCH_SIZE', 'EPOCHS', 'IMAGE_SIZE', 'LR_START', 'LR_MAX', 'LR_MIN', 'LR_RAMPEP', 'LR_DECAY', 'MODEL_SIZE')\n",
    ")\n",
    "wandb.init(\n",
    "    project=\"Mushroom-Classifier\",\n",
    "    tags=[CFG.MODEL, CFG.OPT, 'ExponentialWarmup', str(CFG.CROP_SIZE[0])],\n",
    "    config=config,\n",
    "    dir=\"../\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44793,
     "status": "ok",
     "timestamp": 1697362462918,
     "user": {
      "displayName": "graham broughton",
      "userId": "15728648374086258761"
     },
     "user_tz": 420
    },
    "id": "rPcaVRUTNo76",
    "outputId": "ebaac3a3-53dc-4130-fee7-b4be9cce5a03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 13:10:34.247467: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-12 13:10:34.296752: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-11-12 13:10:35.799623: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-12 13:10:35.799686: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n"
     ]
    }
   ],
   "source": [
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "options = tf.saved_model.SaveOptions(\n",
    "        experimental_io_device=\"/job:localhost\"\n",
    "    )\n",
    "CFG.CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=CFG.ES_PATIENCE,\n",
    "        verbose=1,\n",
    "        mode=\"max\",\n",
    "        restore_best_weights=True,\n",
    "    ),\n",
    "    wandb.keras.WandbMetricsLogger(log_freq=\"batch\"),\n",
    "    wandb.keras.WandbModelCheckpoint(\n",
    "        str(CFG.CKPT_DIR),  # .h5 for weights, dir for whole model\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        options=options,\n",
    "        initial_value_threshold=0.75,\n",
    "    ),\n",
    "    get_lr_callback(CFG.BATCH_SIZE),\n",
    "\n",
    "    # tf.keras.callbacks.TensorBoard(\n",
    "    #     log_dir = logs,\n",
    "    #     histogram_freq = 1,\n",
    "    #     # profile_batch = '500,520'\n",
    "    # )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1734283,
     "status": "ok",
     "timestamp": 1697364199201,
     "user": {
      "displayName": "graham broughton",
      "userId": "15728648374086258761"
     },
     "user_tz": 420
    },
    "id": "fmM3Sf5ONo77",
    "outputId": "c7845e25-c185-40d6-cdfb-c1e52e7df9e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "47/47 [==============================] - 44s 935ms/step - loss: 5.9447 - sparse_categorical_accuracy: 0.0048 - sparse_top_3_categorical_accuracy: 0.0125 - val_loss: 6.1053 - val_sparse_categorical_accuracy: 0.0000e+00 - val_sparse_top_3_categorical_accuracy: 0.0098\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 42s 900ms/step - loss: 5.9466 - sparse_categorical_accuracy: 0.0049 - sparse_top_3_categorical_accuracy: 0.0137 - val_loss: 6.0991 - val_sparse_categorical_accuracy: 0.0039 - val_sparse_top_3_categorical_accuracy: 0.0098\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 42s 893ms/step - loss: 5.9388 - sparse_categorical_accuracy: 0.0052 - sparse_top_3_categorical_accuracy: 0.0125 - val_loss: 6.1144 - val_sparse_categorical_accuracy: 0.0000e+00 - val_sparse_top_3_categorical_accuracy: 0.0020\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 41s 882ms/step - loss: 5.9388 - sparse_categorical_accuracy: 0.0050 - sparse_top_3_categorical_accuracy: 0.0152 - val_loss: 6.1020 - val_sparse_categorical_accuracy: 0.0020 - val_sparse_top_3_categorical_accuracy: 0.0117\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 42s 902ms/step - loss: 5.9435 - sparse_categorical_accuracy: 0.0057 - sparse_top_3_categorical_accuracy: 0.0137 - val_loss: 6.1192 - val_sparse_categorical_accuracy: 0.0020 - val_sparse_top_3_categorical_accuracy: 0.0020\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 41s 883ms/step - loss: 5.9317 - sparse_categorical_accuracy: 0.0064 - sparse_top_3_categorical_accuracy: 0.0140 - val_loss: 6.0995 - val_sparse_categorical_accuracy: 0.0020 - val_sparse_top_3_categorical_accuracy: 0.0078\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - ETA: 0s - loss: 5.9385 - sparse_categorical_accuracy: 0.0040 - sparse_top_3_categorical_accuracy: 0.0119Restoring model weights from the end of the best epoch: 2.\n",
      "47/47 [==============================] - 67s 1s/step - loss: 5.9385 - sparse_categorical_accuracy: 0.0040 - sparse_top_3_categorical_accuracy: 0.0119 - val_loss: 6.1290 - val_sparse_categorical_accuracy: 0.0039 - val_sparse_top_3_categorical_accuracy: 0.0137\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = final_model.fit(\n",
    "    get_batched_dataset(training_filenames, CFG),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=CFG.EPOCHS,\n",
    "    validation_data=get_batched_dataset(validation_filenames, CFG),\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQzOguVCg16L"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_and_save_predictions(model, dataset):\n",
    "    \"\"\"Process a dataset and save the predictions to a CSV file.\n",
    "    Args:\n",
    "    - model: The trained model used for predictions.\n",
    "    - preprocessing_function: Function that preprocesses and returns a dataset from TFRecord files.\n",
    "    - tfrecord_filenames: List of TFRecord filenames to process.\n",
    "\n",
    "    Returns:\n",
    "    - A Pandas DataFrame with columns for Image ID, Prediction, and Actual Label.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    image_ids = []\n",
    "\n",
    "    for (image_data, metadata), label, id in dataset:\n",
    "        # Predict\n",
    "        pred = model.predict((image_data, metadata))\n",
    "        pred_label = pred.argmax(axis=1)  # Get the class with the highest probability\n",
    "\n",
    "        # Extract image ID - adjust this based on your metadata structure\n",
    "        image_id = (\n",
    "            id  # This line needs to be adjusted to your specific metadata structure\n",
    "        )\n",
    "\n",
    "        # Append to lists\n",
    "        predictions.extend(pred_label)\n",
    "        actual_labels.extend(\n",
    "            label.numpy()\n",
    "        )  # Label is already sparse, no need for argmax\n",
    "        image_ids.extend(\n",
    "            image_id.numpy()\n",
    "        )  # Adjust if image_id extraction method is different\n",
    "\n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Image ID\": image_ids,\n",
    "            \"Prediction\": predictions,\n",
    "            \"Actual Label\": actual_labels,\n",
    "        }\n",
    "    )\n",
    "    results_df.to_csv(\"data/predictions.csv\", index=False)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7a95e6bcfca34c5ca67d863895380872",
      "88960c221ba443f5b10a8a63dc773217",
      "e249c6d64080430ca273dacb2cae446f",
      "b707fc265eb1412ebb8d455d32b609d0",
      "d397f7b7138e49a8a6801d96e7a8549b",
      "dc5a275727a745b9851b68716f123861",
      "ccb468c6897448c5ad68ea166f78f027",
      "1c3cc56bb26b46bdab17e364d28c66ed"
     ]
    },
    "executionInfo": {
     "elapsed": 6494,
     "status": "ok",
     "timestamp": 1697364207703,
     "user": {
      "displayName": "graham broughton",
      "userId": "15728648374086258761"
     },
     "user_tz": 420
    },
    "id": "EP-fMeipNfKG",
    "outputId": "b91b04b5-c590-4025-8cee-f42d5f13a8d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-leaf-80</strong> at: <a href='https://wandb.ai/g-broughton/Mushroom-Classifier/runs/1gj7898x' target=\"_blank\">https://wandb.ai/g-broughton/Mushroom-Classifier/runs/1gj7898x</a><br/> View job at <a href='https://wandb.ai/g-broughton/Mushroom-Classifier/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMDExMDI4Mw==/version_details/v2' target=\"_blank\">https://wandb.ai/g-broughton/Mushroom-Classifier/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMDExMDI4Mw==/version_details/v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231026_122647-1gj7898x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact(\n",
    "    \"g-broughton/Mushroom-Classifier/run_fjjcu05u_model:v11\", type=\"model\"\n",
    ")\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpdijuMKjUo7"
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(validation_filenames, CFG)\n",
    "ds = (\n",
    "    ds.map(\n",
    "        lambda x, y, z: ((x, process_meta(y)), z, y[\"id\"]),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "    .batch(512)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "df = process_and_save_predictions(final_model, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = df[df[\"Prediction\"] != df[\"Actual Label\"]]\n",
    "df[\"class\"] = df.apply(lambda x: class_dict[x[\"Actual Label\"]], axis=1)\n",
    "wrong[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[~wrong.index]\n",
    "df[\"class\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1iUOXvvXCq1WNVkG_PUA9YWR5SgaNB6ww",
     "timestamp": 1697270080331
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1c3cc56bb26b46bdab17e364d28c66ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a95e6bcfca34c5ca67d863895380872": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_88960c221ba443f5b10a8a63dc773217",
       "IPY_MODEL_e249c6d64080430ca273dacb2cae446f"
      ],
      "layout": "IPY_MODEL_b707fc265eb1412ebb8d455d32b609d0"
     }
    },
    "88960c221ba443f5b10a8a63dc773217": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d397f7b7138e49a8a6801d96e7a8549b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_dc5a275727a745b9851b68716f123861",
      "value": "4498.752 MB of 4498.795 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "b707fc265eb1412ebb8d455d32b609d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccb468c6897448c5ad68ea166f78f027": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d397f7b7138e49a8a6801d96e7a8549b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc5a275727a745b9851b68716f123861": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e249c6d64080430ca273dacb2cae446f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccb468c6897448c5ad68ea166f78f027",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1c3cc56bb26b46bdab17e364d28c66ed",
      "value": 0.9999903538631951
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
