{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from src.model_creation import predict\n",
    "from src.model_creation import neural_net\n",
    "\n",
    "# The Google Cloud Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# Google Cloud Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Get your Google Cloud project ID from gcloud\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)\n",
    "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
    "    PROJECT_ID = \"bigbucket\"  # @param {type:\"string\"}\n",
    "from datetime import datetime\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
    "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "!sudo apt-get -y -q update\n",
    "!sudo apt-get -y -q install gcsfuse\n",
    "!mkdir -p mush\n",
    "!mkdir -p inat\n",
    "bucket_name='medium_mush'\n",
    "bucket_name2='inatdatabase'\n",
    "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 {bucket_name} mush\n",
    "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 {bucket_name2} inat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(\n",
    "    lr=config[\"INITIAL_LEARNING_RATE\"],\n",
    "    rho=config[\"RMSPROP_RHO\"],\n",
    "    momentum=config[\"RMSPROP_MOMENTUM\"],\n",
    "    epsilon=config[\"RMSPROP_EPSILON\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_neural_network(\n",
    "    base_arch_name = \"effecientnetv2l\",\n",
    "    weights = config['PRETRAINED_MODEL'],\n",
    "    image_size = config['IMAGE_SIZE'],\n",
    "    dropout_pct = config['DROPOUT_PCT'],\n",
    "    n_classes = config['NUM_CLASSES'],\n",
    "    input_dtype = tf.float32,\n",
    "    train_full_network = False)\n",
    "\n",
    "keras.models.load_model(config['FINAL_SAVE_DIR'])\n",
    "\n",
    "model.compile(\n",
    "    loss=config['LOSS'],\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\n",
    "    \"accuracy\", \n",
    "    tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3 accuracy\"),\n",
    "    tf.keras.metrics.TopKCategoricalAccuracy(k=10, name=\"top10 accuracy\")\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, max_prob = predict.make_prediction('file_path', config['IMAGE_SIZE'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
