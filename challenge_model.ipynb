{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":24309,"status":"ok","timestamp":1652852611479,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"B7iiVlutPP4t","outputId":"16565fb8-a0f8-4591-8bf7-ed0c2479de5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Project ID:  \n","deb http://packages.cloud.google.com/apt gcsfuse-bionic main\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  2537  100  2537    0     0  93962      0 --:--:-- --:--:-- --:--:-- 93962\n","OK\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n","Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [770 kB]\n","Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:9 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease [5,391 B]\n","Hit:10 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:14 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 Packages [1,080 B]\n","Hit:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [966 kB]\n","Get:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,199 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,277 kB]\n","Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,503 kB]\n","Get:22 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.3 kB]\n","Get:23 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,765 kB]\n","Get:24 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [932 kB]\n","Get:25 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.8 kB]\n","Fetched 12.8 MB in 2s (6,355 kB/s)\n","Reading package lists...\n","Reading package lists...\n","Building dependency tree...\n","Reading state information...\n","The following packages were automatically installed and are no longer required:\n","  libnvidia-common-460 nsight-compute-2020.2.0\n","Use 'sudo apt autoremove' to remove them.\n","The following NEW packages will be installed:\n","  gcsfuse\n","0 upgraded, 1 newly installed, 0 to remove and 74 not upgraded.\n","Need to get 11.5 MB of archives.\n","After this operation, 27.2 MB of additional disk space will be used.\n","Get:1 http://packages.cloud.google.com/apt gcsfuse-bionic/main amd64 gcsfuse amd64 0.41.1 [11.5 MB]\n","Fetched 11.5 MB in 0s (82.7 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package gcsfuse.\n","(Reading database ... 155203 files and directories currently installed.)\n","Preparing to unpack .../gcsfuse_0.41.1_amd64.deb ...\n","Unpacking gcsfuse (0.41.1) ...\n","Setting up gcsfuse (0.41.1) ...\n","2022/05/18 05:43:31.569505 Start gcsfuse/0.41.1 (Go version go1.17.6) for app \"\" using mount point: /content/mush\n","2022/05/18 05:43:31.582226 Opening GCS connection...\n","2022/05/18 05:43:31.823923 Mounting file system \"medium_mush\"...\n","2022/05/18 05:43:31.824776 File system has been successfully mounted.\n"]}],"source":["import os\n","import numpy as np\n","from PIL import Image\n","import io\n","import re\n","import zipfile\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","import matplotlib.pyplot as plt\n","import tensorflow_datasets as tfds\n","\n","# import fiftyone as fo\n","# import fiftyone.zoo as foz\n","\n","# The Google Cloud Notebook product has specific requirements\n","IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n","\n","# Google Cloud Notebook requires dependencies to be installed with '--user'\n","USER_FLAG = \"\"\n","if IS_GOOGLE_CLOUD_NOTEBOOK:\n","    USER_FLAG = \"--user\"\n","\n","PROJECT_ID = \"\"\n","\n","if not os.getenv(\"IS_TESTING\"):\n","    # Get your Google Cloud project ID from gcloud\n","    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n","    PROJECT_ID = shell_output[0]\n","    print(\"Project ID: \", PROJECT_ID)\n","if PROJECT_ID == \"\" or PROJECT_ID is None:\n","    PROJECT_ID = \"bigbucket\"  # @param {type:\"string\"}\n","from datetime import datetime\n","from google.colab import auth\n","auth.authenticate_user()\n","!echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n","!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n","!sudo apt-get -y -q update\n","!sudo apt-get -y -q install gcsfuse\n","!mkdir -p mush\n","bucket_name='medium_mush'\n","!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 {bucket_name} mush"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":17986,"status":"ok","timestamp":1652852638030,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"rLt8vJ1RYP4_","outputId":"184c80a3-f7ae-4f1c-e1fc-8ab8fbadf315"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.69.168.122:8470\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.69.168.122:8470\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]}],"source":["tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n","strategy = tf.distribute.TPUStrategy(tpu)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":1679,"status":"ok","timestamp":1652854763517,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"fhyShQEbRmVo"},"outputs":[],"source":["import pandas as pd\n","\n","# VALIDATION_BATCH_SIZE = 256\n","# BATCH_SIZE=2\n","# EPOCHS=2\n","# AUTOTUNE = tf.data.AUTOTUNE\n","# IMAGE_SIZE = [331, 331]\n","\n","# if strategy.num_replicas_in_sync == 8: # TPU or 8xGPU\n","#     BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n","#     VALIDATION_BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n","#     start_lr = 0.00001\n","#     min_lr = 0.00001\n","#     max_lr = 0.00005 * strategy.num_replicas_in_sync\n","#     rampup_epochs = 5\n","#     sustain_epochs = 0\n","#     exp_decay = .8\n","\n","# MIXED_PRECISION = True\n","# if MIXED_PRECISION:\n","#     if tpu: \n","#         policy = tf.keras.mixed_precision.Policy('mixed_bfloat16')\n","#     else: #\n","#         policy = tf.keras.mixed_precision.Policy('mixed_float16')\n","#         tf.config.optimizer.set_jit(True) # XLA compilation\n","#     tf.keras.mixed_precision.set_global_policy(policy)\n","#     print('Mixed precision enabled')\n","#### EXPERIMENT PARAMETERS\n","\n","# TENSORBOARD_LOG_DIR   : \"/data-ssd/alex/experiments/slim_export/1608157217/log_dir\"\n","# CHECKPOINT_DIR        : \"/data-ssd/alex/experiments/slim_export/1608157217/checkpoints/ckpt\"\n","# FINAL_SAVE_DIR        : \"/data-ssd/alex/experiments/slim_export/1608157217/final_model/final\"\n","# BACKUP_DIR            : \"/data-ssd/alex/experiments/slim_export/1608157217/backup\"\n","\n","\n","#### DATASET PARAMETERS\n","\n","TRAINING_DATA         = \"/content/t.csv\"\n","VAL_DATA              = \"/content/val.csv\"\n","# TEST_DATA             = \"/data-ssd/alex/datasets/slim_export_20201213/test_cleaned.json\"\n","NUM_CLASSES           = 1394\n","\n","\n","#### TRAINING PARAMETERS\n","\n","# training policy - only use mixed precision=true if you\n","# have a recent NVIDIA GPU that supports CUDA 7.0 or later\n","TRAIN_MIXED_PRECISION = True\n","\n","# size of batch, per gpu\n","BATCH_SIZE            = 256\n","\n","# number of training epochs\n","NUM_EPOCHS            = 10\n","\n","# initial learning rate for the model\n","INITIAL_LEARNING_RATE = 0.05\n","LR_DECAY_FACTOR       = 0.94\n","EPOCHS_PER_LR_DECAY   = 4\n","PRETRAINED_MODEL = False\n","\n","#### MODEL PARAMETERS\n","\n","# neural network architecture\n","MODEL_NAME            = \"xception\"\n","\n","# size of input\n","IMAGE_SIZE            = (299,299)\n","\n","# dropout percentage for layer between pool & logits\n","DROPOUT_PCT           = 0.5\n","\n","# optiimzer\n","OPTIMIZER_NAME  = \"rmsprop\"\n","RMSPROP_RHO     = 0.9\n","RMSPROP_MOMENTUM= 0.9\n","RMSPROP_EPSILON = 1.0\n","\n","MULTIGPU = False\n","DO_LABEL_SMOOTH = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"elapsed":290,"status":"error","timestamp":1652845539996,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"2OrFpgTVUI46","outputId":"61212e2b-f4b9-407a-f236-84ac49814566"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-f79f718c87df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlrfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlrfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-42-f79f718c87df>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlrfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlrfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-42-f79f718c87df>\u001b[0m in \u001b[0;36mlrfn\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_lr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mexp_decay\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrampup_epochs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msustain_epochs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrampup_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msustain_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlr_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlrfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'start_lr' is not defined"]}],"source":["def lrfn(epoch):\n","    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n","        if epoch < rampup_epochs:\n","            lr = (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n","        elif epoch < rampup_epochs + sustain_epochs:\n","            lr = max_lr\n","        else:\n","            lr = (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n","        return lr\n","    return lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay)\n","\n","lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)\n","\n","rng = [i for i in range(EPOCHS)]\n","y = [lrfn(x) for x in rng]\n","plt.plot(rng, [lrfn(x) for x in rng])\n","print(y[0], y[-1])\n","\n","def display_training_curves(training, validation, title, subplot):\n","  if subplot%10==1: # set up the subplots on the first call\n","    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n","    #plt.tight_layout() # bug in tight layout in this version of matplotlib\n","  ax = plt.subplot(subplot)\n","  ax.set_facecolor('#F8F8F8')\n","  ax.plot(training)\n","  ax.plot(validation)\n","  ax.set_title('model '+ title)\n","  ax.set_ylabel(title)\n","  #ax.set_ylim(0.28,1.05)\n","  ax.set_xlabel('epoch')\n","  ax.legend(['train', 'valid.'])\n","\n","  def force_image_sizes(dataset, image_size):\n","    # explicit size will be needed for TPU\n","    reshape_images = lambda image, label: (tf.reshape(image, [*image_size, 3]), label)\n","    dataset = dataset.map(reshape_images, num_parallel_calls=AUTOTUNE)\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":17531,"status":"ok","timestamp":1652831063323,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"W9HD4mnxVi2J","outputId":"b78b7095-eee9-4d26-8674-60820a42b5aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 1s 0us/step\n","83697664/83683744 [==============================] - 1s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," xception (Functional)       (None, 11, 11, 2048)      20861480  \n","                                                                 \n"," global_average_pooling2d (G  (None, 2048)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 5)                 10245     \n","                                                                 \n","=================================================================\n","Total params: 20,871,725\n","Trainable params: 20,817,197\n","Non-trainable params: 54,528\n","_________________________________________________________________\n"]}],"source":["def create_model():\n","    #pretrained_model = tf.keras.applications.MobileNetV2(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n","    pretrained_model = tf.keras.applications.Xception(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n","    #pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n","    #pretrained_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n","    #pretrained_model = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n","    pretrained_model.trainable = True\n","\n","    model = tf.keras.Sequential([\n","        pretrained_model,\n","        tf.keras.layers.GlobalAveragePooling2D(),\n","        #tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(5, activation='softmax', dtype=tf.float32) # the float32 is needed on softmax layer when using mixed precision\n","    ])\n","\n","    model.compile(\n","        optimizer='adam',\n","        loss = 'categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    return model\n","\n","with strategy.scope(): # creating the model in the TPUStrategy scope places the model on the TPU\n","    model = create_model()\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fYCFrnmgc1nw"},"outputs":[],"source":["# def get_training_dataset():\n","#     # dataset = load_dataset(TRAIN_FILENAMES)\n","#     # dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n","#     dataset = dataset.repeat()\n","#     dataset = dataset.shuffle(2048)\n","#     dataset = dataset.batch(BATCH_SIZE)\n","#     dataset = dataset.prefetch(AUTOTUNE) # prefetch next batch while training (autotune prefetch buffer size)\n","#     return dataset\n","\n","# def get_validation_dataset():\n","#     # dataset = load_dataset(VALID_FILENAMES)\n","#     dataset = dataset.batch(VALIDATION_BATCH_SIZE)\n","#     dataset = dataset.prefetch(AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1652847634551,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"uD2cpY37ddhQ","outputId":"93a47246-32cb-45d0-d410-f42c3a658748"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}],"source":["train['full_path'] = 'content/mush/fungi/'+train['file_name']\n","val['full_path'] = 'content/mush/fungi/'+val['file_name']\n","\n","\n","# def parse_image(filename):\n","#     file = tf.io.read_file(filename) # this will work only with filename as tensor\n","#     image = tf.image.decode_image(file)\n","# #     return image\n","\n","# def load(file_path, label):\n","#     img = tf.io.read_file(file_path)\n","#     img = tf.image.decode_png(img, channels=3)\n","#     img = tf.image.convert_image_dtype(img, tf.float32)\n","#     img = tf.image.resize(img, size=IMAGE_SIZE) # optional\n","#     label = tf.cast(tf.equal(label, 'class2'), tf.int32)\n","#     return img, label\n","\n","# ds = tf.data.Dataset.from_tensor_slices((X, y)).map(lambda x, y: load(X, y))\n","\n","# next(iter(ds))\n","\n","\n","\n","# dataset = tf.data.Dataset.from_tensor_slices(X)\n","# dataset.\n","# dataset = dataset.map(lambda x, y:dataset = dataset.map(parse_image).batch(1)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1293,"status":"ok","timestamp":1652852728062,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"lTHI1ARGaF1B"},"outputs":[],"source":["train = pd.read_csv('/content/mush/fungi/training_annot.csv')\n","val = pd.read_csv('/content/mush/fungi/val_annot.csv')\n","\n","#dataset = tf.data.Dataset.from_tensor_slices((train['file_name'], train['category_id']))"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":231,"status":"ok","timestamp":1652854143790,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"Nv6Y767qdSrX"},"outputs":[],"source":["from functools import partial\n","\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","# augments\n","# currently not using rotate\n","def _rotate(x: tf.Tensor, y: tf.Tensor) -> (tf.Tensor, tf.Tensor):\n","    rotate_amt = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n","    x = tf.image.rot90(x, rotate_amt)\n","    return x, y\n","\n","\n","def _flip(x: tf.Tensor, y: tf.Tensor) -> (tf.Tensor, tf.Tensor):\n","    x = tf.image.random_flip_left_right(x)\n","    # right left only\n","    # x = tf.image.random_flip_up_down(x)\n","    return x, y\n","\n","\n","def _color(x: tf.Tensor, y: tf.Tensor) -> (tf.Tensor, tf.Tensor):\n","    x = tf.image.random_hue(x, 0.08)\n","    x = tf.image.random_saturation(x, 0.6, 1.6)\n","    x = tf.image.random_brightness(x, 0.05)\n","    x = tf.image.random_contrast(x, 0.7, 1.3)\n","    return x, y\n","\n","\n","def _random_crop(x: tf.Tensor, y: tf.Tensor) -> (tf.Tensor, tf.Tensor):\n","    bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])\n","\n","    begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(\n","        tf.shape(x),\n","        bounding_boxes=bbox,\n","        area_range=(0.08, 1.0),\n","        aspect_ratio_range=(0.75, 1.33),\n","        max_attempts=100,\n","        min_object_covered=0.1,\n","    )\n","    x = tf.slice(x, begin, size)\n","\n","    return x, y\n","\n","\n","def _decode_img(img):\n","    # convert the compressed string to a 3D uint8 tensor\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n","    img = tf.image.convert_image_dtype(img, tf.float32)\n","    # no resizing, we may augment which will crop.\n","    # we resize _after_ the augments pass\n","    return img\n","\n","\n","def process_row(file_path, label, num_classes):\n","    # load the raw data from the file as a string\n","    img = tf.io.read_file(file_path)\n","    img = _decode_img(img)\n","    # 1 hot encode the label for dense\n","    label = tf.one_hot(label, num_classes)\n","    return img, label\n","\n","\n","def _load_dataframe(dataset_json_path):\n","    df = pd.read_csv(dataset_json_path)\n","\n","    # sort the dataset\n","    df = df.sample(frac=1, random_state=42)\n","    return df\n","\n","\n","def _prepare_dataset(\n","    ds,\n","    image_size=(299, 299),\n","    batch_size=32,\n","    repeat_forever=True,\n","    shuffle_buffer_size=10000,\n","    augment=False,\n","):\n","    # shuffle\n","    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n","\n","    # do transforms for augment or not\n","    if augment:\n","        # crop 100% of the time\n","        ds = ds.map(lambda x, y: _random_crop(x, y), num_parallel_calls=AUTOTUNE)\n","        # flip 50% of the time\n","        # the function already flips 50% of the time, so we call it 100% of the time\n","        ds = ds.map(lambda x, y: _flip(x, y), num_parallel_calls=AUTOTUNE)\n","        # do color 30% of the time\n","        ds = ds.map(\n","            lambda x, y: tf.cond(\n","                tf.random.uniform([], 0, 1) > 0.7, lambda: _color(x, y), lambda: (x, y)\n","            ),\n","            num_parallel_calls=AUTOTUNE,\n","        )\n","        # resize to image size expected by network\n","        ds = ds.map(lambda x, y: (tf.image.resize(x, image_size), y))\n","        # make sure the color transforms haven't move any of the pixels outside of [0,1]\n","        ds = ds.map(\n","            lambda x, y: (tf.clip_by_value(x, 0, 1), y), num_parallel_calls=AUTOTUNE\n","        )\n","    else:\n","        # central crop\n","        # ds = ds.map(lambda x,y: (tf.image.central_crop(x, 0.875), y))\n","        # resize to image size expected by network\n","        ds = ds.map(lambda x, y: (tf.image.resize(x, image_size), y))\n","\n","    # Repeat forever\n","    if repeat_forever:\n","        ds = ds.repeat()\n","\n","    ds = ds.batch(batch_size)\n","\n","    # `prefetch` lets the dataset fetch batches in the background while the model\n","    # is training.\n","    ds = ds.prefetch(buffer_size=AUTOTUNE)\n","\n","    return ds\n","\n","\n","def make_dataset(\n","    path,\n","    label_column_name,\n","    image_size=(299, 299),\n","    batch_size=BATCH_SIZE,\n","    repeat_forever=True,\n","    augment=False,\n","):\n","    df = _load_dataframe(path)\n","    num_examples = len(df)\n","    num_classes = len(df[label_column_name].unique())\n","\n","    ds = tf.data.Dataset.from_tensor_slices((df[\"full_path\"], df[label_column_name]))\n","\n","    process_partial = partial(process_row, num_classes=num_classes)\n","    ds = ds.map(process_partial, num_parallel_calls=AUTOTUNE)\n","\n","    ds = _prepare_dataset(\n","        ds,\n","        image_size=image_size,\n","        batch_size=batch_size,\n","        repeat_forever=repeat_forever,\n","        augment=augment,\n","    )\n","\n","    return (ds, num_examples)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tvvdz4IaVjNQ"},"outputs":[],"source":["training_dataset = get_training_dataset()\n","validation_dataset = get_validation_dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-PSV5xQaXcEw"},"outputs":[],"source":["start_time = time.time()\n","history = model.fit(training_dataset, validation_data=validation_dataset,\n","                    steps_per_epoch=TRAIN_STEPS, epochs=EPOCHS, callbacks=[lr_callback])\n","\n","final_accuracy = history.history[\"val_accuracy\"][-5:]\n","print(\"FINAL ACCURACY MEAN-5: \", np.mean(final_accuracy))\n","print(\"TRAINING TIME: \", time.time() - start_time, \" sec\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"9nDBmMm80RcQ","outputId":"d3b147fb-8130-41c9-b312-1fe4ceb3fd0b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 1s 0us/step\n","83697664/83683744 [==============================] - 1s 0us/step\n","\n","Epoch 1: LearningRateScheduler setting learning rate to 0.05000000074505806.\n","Epoch 1/10\n"," 17/335 [>.............................] - ETA: 1:14:45 - loss: 7.2201 - accuracy: 0.0025 - top3 accuracy: 0.0080 - top10 accuracy: 0.0218"]}],"source":["import os\n","import time\n","import pandas as pd\n","import numpy as np\n","import argparse\n","import yaml\n","\n","import json\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","# def make_training_callbacks(config):\n","\n","def lr_scheduler_fn(epoch):\n","    return INITIAL_LEARNING_RATE * \\\n","        tf.math.pow(LR_DECAY_FACTOR, epoch//EPOCHS_PER_LR_DECAY)\n","callbacks = [\n","            tf.keras.callbacks.LearningRateScheduler(\n","            lr_scheduler_fn,\n","            verbose=1\n","),\n","     ]\n","# return callbacks\n","# keras.callbacks.TensorBoard(\n","#     log_dir=config[\"TENSORBOARD_LOG_DIR\"],\n","#     histogram_freq=0,\n","#     write_graph=False,\n","#     write_images=False,\n","#     update_freq=20,\n","#     profile_batch=0,\n","#     embeddings_freq=0,\n","#     embeddings_metadata={}\n","#),\n","# policy = tf.keras.mixed_precision.Policy('mixed_bfloat16')\n","# tf.keras.mixed_precision.set_global_policy(policy)\n","# tf.keras.callbacks.ModelCheckpoint(\n","#     filepath=config[\"CHECKPOINT_DIR\"],\n","#     save_weights_only=True,\n","#     save_best_only=True,\n","#     monitor=\"val_accuracy\",\n","#     verbose=1\n","# ),\n","# tf.keras.callbacks.experimental.BackupAndRestore(\n","#     backup_dir=config[\"BACKUP_DIR\"],\n","# ),\n","\n","    # def main():\n","# get command line args\n","# parser = argparse.ArgumentParser(description=\"Train an iNat model.\")\n","# parser.add_argument(\n","#     '--config_file',\n","#     required=True,\n","#     help=\"YAML config file for training.\"\n","# )\n","# args = parser.parse_args()\n","# read in config file\n","# if not os.path.exists(args.config_file):\n","#     print(\"No config file.\")\n","#     return\n","# with open(args.config_file, \"r\") as f:\n","#     config = yaml.safe_load(f)\n","\n","# if TRAIN_MIXED_PRECISION:\n","#     from tensorflow.keras.mixed_precision import experimental as mixed_precision\n","#     policy = mixed_precision.Policy('mixed_bfloat16')\n","#     mixed_precision.set_policy(policy)\n","\n","# if MULTIGPU:\n","#     strategy = tf.distribute.MirroredStrategy()\n","# else:\n","#     strategy = tf.distribute.get_strategy()\n","\n","# load train & val datasets\n","if not os.path.exists(TRAINING_DATA):\n","    print(\"Training data file doesn't exist.\")\n","    \n","(train_ds, num_train_examples) = make_dataset(\n","    TRAINING_DATA,\n","    label_column_name='category_id',\n","    image_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE,\n","    repeat_forever=True,\n","    augment=False\n",")\n","if train_ds is None:\n","    print(\"No training dataset.\")\n","\n","    \n","if num_train_examples == 0:\n","    print(\"No training examples.\")\n","    \n","\n","if not os.path.exists(VAL_DATA):\n","    print(\"Validation data file doesn't exist.\")\n","    \n","(val_ds, num_val_examples) = make_dataset(\n","    VAL_DATA,\n","    label_column_name='category_id',\n","    image_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE,\n","    repeat_forever=True,\n","    augment=False\n",")\n","if val_ds is None:\n","    print(\"No val dataset.\")\n","    \n","if num_val_examples == 0:\n","    print(\"No val examples.\")\n","    \n","    # load pretrained model\n","    if False and PRETRAINED_MODEL != \"imagenet\" and os.path.exists(PRETRAINED_MODEL):\n","         model.load_weights(PRETRAINED_MODEL, by_name=True)\n","    if model is None:\n","        print(\"No model to train.\")\n","        \n","if DO_LABEL_SMOOTH:\n","    if LABEL_SMOOTH_MODE == \"flat\":\n","         # with flat label smoothing we can do it all\n","         # in the loss function\n","        loss=tf.keras.losses.CategoricalCrossentropy(\n","        label_smoothing=LABEL_SMOOTH_PCT\n","        )\n","    else:\n","        # with parent/heirarchical label smoothing\n","        # we can't do it in the loss function, we have\n","        # to adjust the labels in the dataset\n","        print(\"Unsupported label smoothing mode.\")\n","        \n","else:\n","    loss=tf.keras.losses.CategoricalCrossentropy()\n","     # compile the network for training\n","with strategy.scope():\n","    # create optimizer for neural network\n","    optimizer = keras.optimizers.RMSprop(\n","        lr=INITIAL_LEARNING_RATE,\n","        rho=RMSPROP_RHO,\n","        momentum=RMSPROP_MOMENTUM,\n","        epsilon=RMSPROP_EPSILON\n","    )    # create neural network\n","    model = make_neural_network(\n","        base_arch_name = \"xception\",\n","        weights = 'imagenet',\n","        image_size = IMAGE_SIZE,\n","        dropout_pct = DROPOUT_PCT,\n","        n_classes = NUM_CLASSES,\n","        input_dtype = 'float32',\n","        train_full_network = True)\n","    model.compile(\n","        loss=loss,\n","        optimizer=optimizer,\n","        metrics=[\n","            \"accuracy\", \n","            tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3 accuracy\"),\n","            tf.keras.metrics.TopKCategoricalAccuracy(k=10, name=\"top10 accuracy\")\n","    ]\n",")\n"," # setup callbacks\n","# training_callbacks = make_training_callbacks(config)\n","STEPS_PER_EPOCH = np.ceil(num_train_examples/BATCH_SIZE)\n","VAL_STEPS = np.ceil(num_val_examples/BATCH_SIZE)\n","start = time.time()\n","hisory = model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    validation_steps=VAL_STEPS,\n","    epochs=NUM_EPOCHS,\n","    steps_per_epoch=STEPS_PER_EPOCH,\n","    callbacks=callbacks\n",")\n","end = time.time()\n","print(\"time elapsed during fit: {:.1f}\".format(end-start))\n","print(history.history)\n","# model.save(FINAL_SAVE_DIR)\n","# if __name__ == \"__main__\":\n","#     main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DXaQqnlL1OzH"},"outputs":[],"source":["|import pandas as pd"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":518,"status":"ok","timestamp":1652852801478,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"AG3PRc5l_m_s"},"outputs":[],"source":["train = train[['file_name', 'category_id']]\n","train['full_path'] = 'gs://medium_mush/fungi/' + train['file_name']\n","val = val[['file_name', 'category_id']]\n","val['full_path'] = 'gs://medium_mush/fungi/' + val['file_name']\n","val.to_csv('val.csv', index=False)\n","train.to_csv('t.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_J3gCLBn_t58"},"outputs":[],"source":["val = pd.read_csv('/content/mush/fungi/val_annot.csv')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":121,"status":"ok","timestamp":1652852819927,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"Z6nTEzwBAhGU"},"outputs":[],"source":["def make_neural_network(base_arch_name, weights, image_size, dropout_pct, n_classes, input_dtype, train_full_network):\n","    image_size_with_channels = image_size \n","    base_arch = keras.applications.Xception if base_arch_name == \"xception\" else None\n","    if not base_arch:\n","        print(\"Unsupported base architecture.\")\n","        return None\n","\n","    input_layer = keras.layers.Input(shape=(299, 299, 3), dtype=input_dtype)\n","    base_model = base_arch(input_tensor=input_layer, weights=weights, include_top=False)\n","    avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n","    dropout = keras.layers.Dropout(dropout_pct)(avg)\n","    x = keras.layers.Dense(1394, name=\"dense_logits\")(dropout)\n","    output = keras.layers.Activation(\"softmax\", dtype=\"float32\", name=\"predictions\")(x)\n","    model = keras.Model(inputs=base_model.input, outputs=output)\n","\n","    if train_full_network:\n","        for layer in base_model.layers:\n","            layer.trainable = True\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1652842820467,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"LphSoHMnAjBL","outputId":"bdd86123-8c2f-475b-87f8-ae4f8d4bd0e4"},"outputs":[{"data":{"text/plain":["1394"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["len(train['category_id'].unique())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":350,"status":"error","timestamp":1652843427855,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"pxpxpRFwG_DD","outputId":"f7f050f9-de68-4177-909a-29a470ea4a0c"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-9e4cad303c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVAL_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["        start = time.time()\n","        history = model.fit(\n","            train_ds,\n","            validation_data=val_ds,\n","            validation_steps=VAL_STEPS,\n","            epochs=NUM_EPOCHS,\n","            steps_per_epoch=STEPS_PER_EPOCH,\n","            callbacks=training_callbacks\n","        )\n","\n","        end = time.time()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1652846512296,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"dS4x-YSCJTUz","outputId":"36ca30c1-e689-4c87-f9a4-d6daaffbf190"},"outputs":[{"data":{"text/plain":["<PrefetchDataset element_spec=(TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1394), dtype=tf.float32, name=None))>"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["val_ds"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":128,"status":"ok","timestamp":1652852807995,"user":{"displayName":"graham broughton","userId":"15728648374086258761"},"user_tz":420},"id":"FPRqF_sAVBmp","outputId":"f6f6fefb-f471-4e34-8fe7-e2d7dcedfa1e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              file_name  category_id  \\\n","0     images/16390_Leucoagaricus_leucothites/JM2009P...          650   \n","1     images/16390_Leucoagaricus_leucothites/JM2012P...          650   \n","2     images/16390_Leucoagaricus_leucothites/MC2009P...          650   \n","3     images/40985_Byssomerulius_corium/MC2009PIC320...         1158   \n","4     images/40985_Byssomerulius_corium/MC2017-91902...         1158   \n","...                                                 ...          ...   \n","4177  images/16365_Leptosporomyces_fuscostratus/ML20...          648   \n","4178  images/16365_Leptosporomyces_fuscostratus/ML20...          648   \n","4179  images/16382_Leucoagaricus_leucothites var. ca...          649   \n","4180  images/16382_Leucoagaricus_leucothites var. ca...          649   \n","4181  images/16382_Leucoagaricus_leucothites var. ca...          649   \n","\n","                                              full_path  \n","0     gs://medium_mush/fungi/images/16390_Leucoagari...  \n","1     gs://medium_mush/fungi/images/16390_Leucoagari...  \n","2     gs://medium_mush/fungi/images/16390_Leucoagari...  \n","3     gs://medium_mush/fungi/images/40985_Byssomerul...  \n","4     gs://medium_mush/fungi/images/40985_Byssomerul...  \n","...                                                 ...  \n","4177  gs://medium_mush/fungi/images/16365_Leptosporo...  \n","4178  gs://medium_mush/fungi/images/16365_Leptosporo...  \n","4179  gs://medium_mush/fungi/images/16382_Leucoagari...  \n","4180  gs://medium_mush/fungi/images/16382_Leucoagari...  \n","4181  gs://medium_mush/fungi/images/16382_Leucoagari...  \n","\n","[4182 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-892235bd-ee8e-4a72-b4a6-d34b067d09a6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>category_id</th>\n","      <th>full_path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>images/16390_Leucoagaricus_leucothites/JM2009P...</td>\n","      <td>650</td>\n","      <td>gs://medium_mush/fungi/images/16390_Leucoagari...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>images/16390_Leucoagaricus_leucothites/JM2012P...</td>\n","      <td>650</td>\n","      <td>gs://medium_mush/fungi/images/16390_Leucoagari...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>images/16390_Leucoagaricus_leucothites/MC2009P...</td>\n","      <td>650</td>\n","      <td>gs://medium_mush/fungi/images/16390_Leucoagari...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>images/40985_Byssomerulius_corium/MC2009PIC320...</td>\n","      <td>1158</td>\n","      <td>gs://medium_mush/fungi/images/40985_Byssomerul...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>images/40985_Byssomerulius_corium/MC2017-91902...</td>\n","      <td>1158</td>\n","      <td>gs://medium_mush/fungi/images/40985_Byssomerul...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4177</th>\n","      <td>images/16365_Leptosporomyces_fuscostratus/ML20...</td>\n","      <td>648</td>\n","      <td>gs://medium_mush/fungi/images/16365_Leptosporo...</td>\n","    </tr>\n","    <tr>\n","      <th>4178</th>\n","      <td>images/16365_Leptosporomyces_fuscostratus/ML20...</td>\n","      <td>648</td>\n","      <td>gs://medium_mush/fungi/images/16365_Leptosporo...</td>\n","    </tr>\n","    <tr>\n","      <th>4179</th>\n","      <td>images/16382_Leucoagaricus_leucothites var. ca...</td>\n","      <td>649</td>\n","      <td>gs://medium_mush/fungi/images/16382_Leucoagari...</td>\n","    </tr>\n","    <tr>\n","      <th>4180</th>\n","      <td>images/16382_Leucoagaricus_leucothites var. ca...</td>\n","      <td>649</td>\n","      <td>gs://medium_mush/fungi/images/16382_Leucoagari...</td>\n","    </tr>\n","    <tr>\n","      <th>4181</th>\n","      <td>images/16382_Leucoagaricus_leucothites var. ca...</td>\n","      <td>649</td>\n","      <td>gs://medium_mush/fungi/images/16382_Leucoagari...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4182 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-892235bd-ee8e-4a72-b4a6-d34b067d09a6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-892235bd-ee8e-4a72-b4a6-d34b067d09a6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-892235bd-ee8e-4a72-b4a6-d34b067d09a6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}],"source":["val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L5rOQSKsaq-g"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"challenge_model.ipynb","provenance":[],"mount_file_id":"1RHMlCXL_E9qyHSczFRBb3rqi_vVU5rYY","authorship_tag":"ABX9TyPNTmSZPtzYVEjT3BL2REBZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}